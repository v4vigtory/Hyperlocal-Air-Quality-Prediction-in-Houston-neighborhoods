{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import basic python packages for data analysis and plotting\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import matplotlib.lines as mlines\n",
    "import pylab as plot\n",
    "import matplotlib\n",
    "import random\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (A) Dataset prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all datasets to create master_df\n",
    "\n",
    "root = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "\n",
    "df_aq = pd.read_csv(root + \"/data/cleaned/air_quality_NO2.csv\", index_col=0)[['value','latitude', 'longitude']]\n",
    "df_met = pd.read_csv(root + \"/data/cleaned/nO2_met.csv\", index_col=0)\n",
    "df_fac = pd.read_csv(root + \"/data/cleaned/no2_fac_data.csv\", index_col=0)\n",
    "# df_fac.drop(df_fac.columns[df_fac.columns.str.contains('_emsdist')], axis=1, inplace=True)\n",
    "df_traffic = pd.read_csv(root + \"/data/cleaned/intersection_final.csv\", index_col=0)\n",
    "\n",
    "df_m1 = df_aq.merge(df_met, on = ['latitude', 'longitude'], how = 'inner')\n",
    "df_m2 = df_m1.merge(df_fac, on = ['latitude', 'longitude'], how = 'inner')\n",
    "df_merged = df_m2.merge(df_traffic, on = ['latitude', 'longitude'], how = 'inner')\n",
    "df_merged.drop(columns = ['latitude', 'longitude'], inplace=True)\n",
    "\n",
    "X = df_merged.drop(\"value\",1) \n",
    "y = df_merged[\"value\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to scale and transform input data\n",
    "# def get_data(X, y):\n",
    "#     X = X.values\n",
    "#     y = y.values\n",
    "#     # scaling the data\n",
    "#     feature_scaler = StandardScaler()\n",
    "#     X = feature_scaler.fit_transform(X)\n",
    "#     return X, y\n",
    "\n",
    "# # acquiring transformed data\n",
    "# X_arr, y_arr = get_data(X, y)\n",
    "\n",
    "# # splitting into test and train\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_arr, y_arr, test_size=0.3)\n",
    "# cols = np.array(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting into test and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(X), np.array(y), test_size=0.3, random_state=30)\n",
    "cols = np.array(X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (B) Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset class for feeding in data\n",
    "torch.manual_seed(237943)\n",
    "class AirQualityDataset(torch.utils.data.Dataset):\n",
    "\n",
    "  def __init__(self, X_arr, y_arr):\n",
    "    self.x_data = torch.tensor(X_arr, \\\n",
    "      dtype=torch.float32)\n",
    "    self.y_data = torch.tensor(y_arr, \\\n",
    "      dtype=torch.float32)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.x_data)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    preds = self.x_data[idx,:]  # or just [idx]\n",
    "    conc = self.y_data[idx] \n",
    "    return (preds, conc)       # tuple of matrices\n",
    "\n",
    "# prepping data for training\n",
    "batch_size = 5\n",
    "train_ds = AirQualityDataset(X_train, y_train)\n",
    "test_ds = AirQualityDataset(X_test, y_test)\n",
    "train_ldr = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "test_ldr = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network architecture\n",
    "class NeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.linear_tanh_stack = torch.nn.Sequential(\n",
    "            torch.nn.Linear(82, 60),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(60, 60),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(60, 40),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(40, 30),\n",
    "            torch.nn.Tanh(),\n",
    "#             torch.nn.Dropout(p=0.1),\n",
    "            torch.nn.Linear(30, 20),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(20, 20),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(20,10),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(10, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        pred_conc = self.linear_tanh_stack(x)\n",
    "        return pred_conc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (linear_tanh_stack): Sequential(\n",
      "    (0): Linear(in_features=82, out_features=60, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=60, out_features=60, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=60, out_features=40, bias=True)\n",
      "    (5): Tanh()\n",
      "    (6): Linear(in_features=40, out_features=30, bias=True)\n",
      "    (7): Tanh()\n",
      "    (8): Linear(in_features=30, out_features=20, bias=True)\n",
      "    (9): Tanh()\n",
      "    (10): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (11): Tanh()\n",
      "    (12): Linear(in_features=20, out_features=10, bias=True)\n",
      "    (13): Tanh()\n",
      "    (14): Linear(in_features=10, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Layer: linear_tanh_stack.0.weight | Size: torch.Size([60, 82]) | Values : tensor([[-0.0805,  0.0095,  0.0651, -0.0526, -0.0743, -0.0443,  0.0905, -0.0364,\n",
      "          0.0597, -0.0998,  0.0228,  0.0688,  0.0926, -0.0531, -0.0602,  0.0254,\n",
      "          0.0146,  0.0328,  0.0015, -0.0469, -0.0938,  0.0495,  0.0333, -0.0580,\n",
      "         -0.0489,  0.0238,  0.0304,  0.0472,  0.0575,  0.0006, -0.0555,  0.0620,\n",
      "         -0.0074,  0.0033, -0.0209,  0.0092,  0.0471, -0.0901, -0.1000, -0.0953,\n",
      "         -0.0983, -0.0384,  0.0096,  0.0594, -0.0023,  0.0452, -0.0047,  0.0455,\n",
      "         -0.0853, -0.0060, -0.0025,  0.0803, -0.1084,  0.0969,  0.0230,  0.0079,\n",
      "         -0.0933,  0.1093,  0.0246, -0.0450,  0.0519,  0.0294, -0.0742, -0.0449,\n",
      "          0.0762, -0.0144,  0.0309, -0.1050,  0.0888,  0.0991,  0.0347,  0.0167,\n",
      "         -0.0959,  0.1096,  0.0894,  0.0407,  0.0259,  0.0165, -0.0624, -0.0961,\n",
      "          0.0519, -0.0831],\n",
      "        [ 0.0173, -0.0061,  0.1094,  0.0903,  0.0348,  0.0774, -0.0703,  0.0908,\n",
      "         -0.0179, -0.1089, -0.0368, -0.0765, -0.0085, -0.0070,  0.0581,  0.0597,\n",
      "          0.0713, -0.0920,  0.0689, -0.0089, -0.0826,  0.1077, -0.0280, -0.1089,\n",
      "          0.0006,  0.0695, -0.1097, -0.0810, -0.0340, -0.0729,  0.0176,  0.0594,\n",
      "         -0.0632,  0.0549, -0.1085,  0.0298, -0.0096, -0.0869, -0.0571, -0.0226,\n",
      "         -0.0174,  0.0058,  0.0131, -0.0328,  0.0775,  0.0942, -0.0720,  0.0108,\n",
      "          0.0542, -0.0201,  0.1005, -0.0575,  0.0195, -0.0004, -0.0710,  0.0242,\n",
      "          0.1011, -0.0507, -0.0411, -0.1052, -0.0455, -0.0133,  0.0283,  0.0723,\n",
      "          0.0265, -0.0406, -0.0014, -0.0250,  0.0956,  0.0844,  0.0240, -0.0842,\n",
      "          0.0005,  0.0856,  0.0024,  0.0833,  0.0565, -0.0767,  0.0551, -0.0738,\n",
      "          0.0555,  0.0604]], grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_tanh_stack.0.bias | Size: torch.Size([60]) | Values : tensor([-0.0670, -0.1048], grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_tanh_stack.2.weight | Size: torch.Size([60, 60]) | Values : tensor([[-0.0123,  0.0096, -0.0129, -0.0850, -0.1168, -0.1096,  0.0076, -0.1123,\n",
      "          0.1084,  0.0187,  0.0137,  0.0324, -0.0744, -0.0835, -0.1195, -0.0371,\n",
      "         -0.0418,  0.0742,  0.0925, -0.1104,  0.0107, -0.0003,  0.0875, -0.1273,\n",
      "         -0.0781, -0.0814, -0.0782,  0.0961,  0.0118, -0.0291, -0.1265,  0.0262,\n",
      "          0.0646,  0.0586,  0.0737,  0.1078, -0.0514,  0.0039, -0.0753, -0.1024,\n",
      "         -0.0232, -0.0261, -0.0478, -0.0203,  0.1151, -0.0971,  0.0611,  0.0716,\n",
      "         -0.0582, -0.0643,  0.1081, -0.1056,  0.0470,  0.0319, -0.1238,  0.0295,\n",
      "         -0.1215, -0.1077, -0.0874,  0.0155],\n",
      "        [ 0.1221, -0.1188,  0.0201,  0.0173,  0.0177, -0.0013,  0.0654,  0.0018,\n",
      "         -0.0459,  0.0123, -0.0826, -0.0713,  0.1213, -0.0830, -0.0297,  0.0150,\n",
      "         -0.0149,  0.1039, -0.0281,  0.0651, -0.0898, -0.0892, -0.1261,  0.0483,\n",
      "          0.0943,  0.0631, -0.0769,  0.0044, -0.1086,  0.0107,  0.0040, -0.0491,\n",
      "         -0.0571, -0.0290,  0.0429, -0.1095,  0.0162, -0.0784,  0.0956,  0.0746,\n",
      "          0.1223,  0.0181,  0.0833,  0.0844,  0.1199, -0.1040, -0.1006,  0.0612,\n",
      "         -0.0079,  0.0546, -0.0028,  0.0800,  0.1245, -0.1051, -0.0900, -0.0298,\n",
      "          0.0159, -0.0276, -0.0193,  0.0843]], grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_tanh_stack.2.bias | Size: torch.Size([60]) | Values : tensor([0.0326, 0.0292], grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_tanh_stack.4.weight | Size: torch.Size([40, 60]) | Values : tensor([[ 0.0852, -0.0472, -0.0252, -0.0120, -0.0070,  0.0807, -0.0957,  0.0466,\n",
      "          0.0364, -0.0208, -0.1206,  0.0364,  0.0456,  0.0696, -0.1111, -0.0327,\n",
      "          0.1098, -0.0425,  0.0713, -0.0832,  0.1248, -0.0190,  0.0732,  0.0066,\n",
      "          0.0124, -0.1053,  0.0598,  0.0099, -0.0507, -0.1066, -0.0495, -0.0590,\n",
      "         -0.0773, -0.1177,  0.0880, -0.0280, -0.1138, -0.0462, -0.0288,  0.0732,\n",
      "         -0.1058,  0.1163, -0.0032,  0.1149,  0.0243, -0.1263,  0.0113, -0.0083,\n",
      "         -0.0682,  0.0529, -0.1212,  0.0397, -0.0221, -0.0535, -0.0258, -0.0622,\n",
      "         -0.0023, -0.0402,  0.0944, -0.0713],\n",
      "        [ 0.0872, -0.0357,  0.0911,  0.0185, -0.0459,  0.0757,  0.0085,  0.0178,\n",
      "          0.0983,  0.0294, -0.1164, -0.0423, -0.1176,  0.0240,  0.0969,  0.0725,\n",
      "         -0.0046,  0.1163,  0.0002,  0.0199, -0.1099,  0.0837, -0.0637,  0.0970,\n",
      "         -0.0097, -0.1232, -0.0290, -0.0466,  0.0478, -0.0972, -0.0882,  0.0876,\n",
      "         -0.0531,  0.0980,  0.1160,  0.0581,  0.0040,  0.0416,  0.0819,  0.0231,\n",
      "          0.0161, -0.0447, -0.0440,  0.0283,  0.1142, -0.1051,  0.0652,  0.0844,\n",
      "         -0.0145, -0.1285,  0.0107,  0.0006,  0.0977, -0.1183, -0.0686,  0.0130,\n",
      "          0.1221,  0.0786, -0.0647,  0.0090]], grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_tanh_stack.4.bias | Size: torch.Size([40]) | Values : tensor([-0.0905, -0.0355], grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_tanh_stack.6.weight | Size: torch.Size([30, 40]) | Values : tensor([[-0.0908, -0.1239,  0.1143, -0.0705,  0.1146,  0.1038, -0.0108, -0.1466,\n",
      "         -0.1370,  0.0668, -0.0829, -0.0701, -0.0896, -0.0719,  0.1062, -0.0515,\n",
      "         -0.0812,  0.0993, -0.1531,  0.0844,  0.0978,  0.0782, -0.1554, -0.1503,\n",
      "         -0.0954, -0.1128, -0.0171, -0.0613, -0.0173,  0.1376,  0.1336, -0.1512,\n",
      "         -0.1423, -0.0400,  0.1544, -0.0620,  0.1239,  0.0034, -0.0881,  0.0063],\n",
      "        [ 0.0563,  0.1487, -0.0179,  0.0938, -0.1277, -0.1101,  0.0343,  0.0447,\n",
      "         -0.0767,  0.1432,  0.1165,  0.0632, -0.0700, -0.0311,  0.1121, -0.1386,\n",
      "         -0.0527,  0.0652,  0.0769,  0.1376, -0.0406, -0.0690,  0.0990,  0.0338,\n",
      "         -0.0168,  0.1300, -0.1545,  0.0922, -0.1383,  0.0540, -0.1473, -0.1290,\n",
      "          0.0113, -0.0959, -0.0668, -0.0141, -0.1111,  0.1195,  0.0439,  0.0718]],\n",
      "       grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_tanh_stack.6.bias | Size: torch.Size([30]) | Values : tensor([ 0.1530, -0.0522], grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_tanh_stack.8.weight | Size: torch.Size([20, 30]) | Values : tensor([[-0.1157, -0.0804, -0.0893, -0.0224,  0.1641, -0.0138,  0.0753, -0.1777,\n",
      "         -0.0004, -0.1025,  0.0961, -0.0285,  0.0311,  0.0450, -0.1242, -0.0313,\n",
      "          0.1541, -0.1281,  0.1349,  0.1632,  0.0231,  0.1493, -0.0547, -0.1437,\n",
      "          0.0970,  0.1183,  0.0650,  0.1296,  0.1233, -0.1641],\n",
      "        [ 0.0798, -0.0148, -0.1596, -0.0083, -0.0233,  0.1012, -0.1216,  0.0170,\n",
      "         -0.1057, -0.1033,  0.0519, -0.0353,  0.0690,  0.0314,  0.1161,  0.0195,\n",
      "         -0.0920,  0.1475,  0.0718,  0.0346, -0.0957,  0.0753,  0.1626, -0.0635,\n",
      "         -0.0196, -0.0765,  0.0072, -0.0582,  0.0200, -0.0326]],\n",
      "       grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_tanh_stack.8.bias | Size: torch.Size([20]) | Values : tensor([ 0.1244, -0.1641], grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_tanh_stack.10.weight | Size: torch.Size([20, 20]) | Values : tensor([[ 0.1112,  0.1858, -0.1673, -0.1452,  0.1354, -0.1107,  0.0129,  0.1346,\n",
      "          0.2137,  0.1595, -0.0115,  0.0841, -0.0237,  0.2011,  0.2130,  0.1152,\n",
      "         -0.0021, -0.1533,  0.1503, -0.0655],\n",
      "        [ 0.0409, -0.1649,  0.1487,  0.0800,  0.0951, -0.0710,  0.0912, -0.2158,\n",
      "          0.2148,  0.0949, -0.1327, -0.0128, -0.0776,  0.0972,  0.2056,  0.1851,\n",
      "         -0.1559, -0.0218,  0.1131, -0.1374]], grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_tanh_stack.10.bias | Size: torch.Size([20]) | Values : tensor([-0.2095, -0.2001], grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_tanh_stack.12.weight | Size: torch.Size([10, 20]) | Values : tensor([[-0.0566,  0.2153,  0.1995,  0.0808, -0.1373, -0.1335,  0.1371,  0.1765,\n",
      "          0.1098,  0.0313, -0.0627, -0.1082,  0.0310,  0.0973, -0.1011,  0.1952,\n",
      "         -0.0623, -0.0061, -0.2106,  0.0788],\n",
      "        [-0.1953, -0.1408, -0.1116, -0.1498,  0.0235, -0.0067, -0.0419, -0.1136,\n",
      "         -0.1915, -0.0033, -0.0752,  0.1171,  0.1020,  0.2186,  0.1918, -0.1777,\n",
      "         -0.0040, -0.1955,  0.1265,  0.0151]], grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_tanh_stack.12.bias | Size: torch.Size([10]) | Values : tensor([-0.1480,  0.1728], grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_tanh_stack.14.weight | Size: torch.Size([1, 10]) | Values : tensor([[ 0.0249,  0.1554,  0.1046, -0.2171,  0.2755,  0.3006, -0.2473,  0.1918,\n",
      "          0.1436, -0.2846]], grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_tanh_stack.14.bias | Size: torch.Size([1]) | Values : tensor([-0.1725], grad_fn=<SliceBackward>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# creating model instance\n",
    "model = NeuralNetwork()\n",
    "print(model)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")\n",
    "    \n",
    "# initialising hyperparameters\n",
    "learning_rate = 1e-2\n",
    "epochs = 30\n",
    "\n",
    "# initializing the loss function\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# initializing the optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining train and test loops\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss}  [{current}/{size}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Test Error: Avg loss: {test_loss} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.13525862991809845  [0/7511]\n",
      "loss: 1.3660488548339345e-05  [500/7511]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaverichhikara/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([5, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.6278855784767075e-06  [1000/7511]\n",
      "loss: 1.5683312085457146e-05  [1500/7511]\n",
      "loss: 9.571062946633901e-06  [2000/7511]\n",
      "loss: 7.448089945683023e-06  [2500/7511]\n",
      "loss: 3.920215021935292e-06  [3000/7511]\n",
      "loss: 7.8261773523991e-06  [3500/7511]\n",
      "loss: 1.3340118130145129e-05  [4000/7511]\n",
      "loss: 9.444209354114719e-06  [4500/7511]\n",
      "loss: 6.588407359231496e-06  [5000/7511]\n",
      "loss: 5.463972456709598e-07  [5500/7511]\n",
      "loss: 1.2945363323524361e-06  [6000/7511]\n",
      "loss: 8.421853635809384e-06  [6500/7511]\n",
      "loss: 1.2145474101998843e-06  [7000/7511]\n",
      "loss: 6.746405460944516e-07  [7500/7511]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaverichhikara/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/Users/kaverichhikara/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([4])) that is different to the input size (torch.Size([4, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: Avg loss: 7.883603984185755e-06 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.00025659549282863736  [0/7511]\n",
      "loss: 3.317557911941549e-06  [500/7511]\n",
      "loss: 8.786929356574547e-06  [1000/7511]\n",
      "loss: 1.0637850209604949e-05  [1500/7511]\n",
      "loss: 8.748455002205446e-06  [2000/7511]\n",
      "loss: 2.618554617583868e-06  [2500/7511]\n",
      "loss: 7.790486961312126e-06  [3000/7511]\n",
      "loss: 1.1090861335105728e-05  [3500/7511]\n",
      "loss: 2.4572159418312367e-06  [4000/7511]\n",
      "loss: 5.238321136857849e-06  [4500/7511]\n",
      "loss: 1.3669018699147273e-06  [5000/7511]\n",
      "loss: 1.1783767149609048e-05  [5500/7511]\n",
      "loss: 1.684222070252872e-06  [6000/7511]\n",
      "loss: 1.6944255548878573e-05  [6500/7511]\n",
      "loss: 1.4617349734180607e-05  [7000/7511]\n",
      "loss: 7.78377000187902e-07  [7500/7511]\n",
      "Test Error: Avg loss: 5.75178847311531e-06 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 4.9541004045750014e-06  [0/7511]\n",
      "loss: 1.3472847513185116e-06  [500/7511]\n",
      "loss: 2.063224201265257e-06  [1000/7511]\n",
      "loss: 3.150746351820999e-06  [1500/7511]\n",
      "loss: 6.470157586591085e-06  [2000/7511]\n",
      "loss: 8.8990964286495e-07  [2500/7511]\n",
      "loss: 3.0679896667606954e-07  [3000/7511]\n",
      "loss: 5.5486175369878765e-06  [3500/7511]\n",
      "loss: 3.5658936212712433e-06  [4000/7511]\n",
      "loss: 3.200470473530004e-06  [4500/7511]\n",
      "loss: 4.001688012067461e-06  [5000/7511]\n",
      "loss: 2.1828266199008795e-06  [5500/7511]\n",
      "loss: 1.9808280740107875e-06  [6000/7511]\n",
      "loss: 1.9489370970404707e-06  [6500/7511]\n",
      "loss: 9.20339152798988e-06  [7000/7511]\n",
      "loss: 1.2828646731577464e-06  [7500/7511]\n",
      "Test Error: Avg loss: 4.7855246360187975e-06 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.0232469094262342e-06  [0/7511]\n",
      "loss: 2.974359858853859e-06  [500/7511]\n",
      "loss: 1.0969690265483223e-05  [1000/7511]\n",
      "loss: 1.6936367046582745e-06  [1500/7511]\n",
      "loss: 2.1178817632971914e-07  [2000/7511]\n",
      "loss: 8.284100516675608e-08  [2500/7511]\n",
      "loss: 2.95738300337689e-06  [3000/7511]\n",
      "loss: 2.3154184702889324e-07  [3500/7511]\n",
      "loss: 3.526884256643825e-06  [4000/7511]\n",
      "loss: 3.3734506814653287e-06  [4500/7511]\n",
      "loss: 3.610060275605065e-06  [5000/7511]\n",
      "loss: 1.888414431050478e-06  [5500/7511]\n",
      "loss: 3.333445420139469e-06  [6000/7511]\n",
      "loss: 8.341189072780253e-08  [6500/7511]\n",
      "loss: 1.3006338406285067e-07  [7000/7511]\n",
      "loss: 5.209980827203253e-06  [7500/7511]\n",
      "Test Error: Avg loss: 4.527151462767651e-06 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 5.970784059172729e-06  [0/7511]\n",
      "loss: 5.989826235008877e-08  [500/7511]\n",
      "loss: 3.652709892776329e-06  [1000/7511]\n",
      "loss: 2.197174126195023e-06  [1500/7511]\n",
      "loss: 5.118126409797696e-06  [2000/7511]\n",
      "loss: 3.151450300720171e-06  [2500/7511]\n",
      "loss: 1.4758680890736287e-06  [3000/7511]\n",
      "loss: 8.656372187942907e-07  [3500/7511]\n",
      "loss: 1.187005523206608e-06  [4000/7511]\n",
      "loss: 7.724824172328226e-06  [4500/7511]\n",
      "loss: 3.5259529340692097e-07  [5000/7511]\n",
      "loss: 1.444860345145571e-06  [5500/7511]\n",
      "loss: 1.7711630562189384e-06  [6000/7511]\n",
      "loss: 1.5288602526197792e-06  [6500/7511]\n",
      "loss: 2.5816348170337733e-06  [7000/7511]\n",
      "loss: 1.4318147805170156e-06  [7500/7511]\n",
      "Test Error: Avg loss: 4.28773049290494e-06 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.5304682392525137e-06  [0/7511]\n",
      "loss: 1.9483131836750545e-06  [500/7511]\n",
      "loss: 2.084088009723928e-06  [1000/7511]\n",
      "loss: 4.0477755192114273e-07  [1500/7511]\n",
      "loss: 3.090354766754899e-06  [2000/7511]\n",
      "loss: 2.361750603085966e-06  [2500/7511]\n",
      "loss: 6.582017419987096e-08  [3000/7511]\n",
      "loss: 2.9248817554616835e-06  [3500/7511]\n",
      "loss: 8.686220098752528e-08  [4000/7511]\n",
      "loss: 3.472899152257014e-06  [4500/7511]\n",
      "loss: 1.0967590924337856e-06  [5000/7511]\n",
      "loss: 6.809227670601103e-08  [5500/7511]\n",
      "loss: 1.919027818075847e-05  [6000/7511]\n",
      "loss: 1.2155164768046234e-06  [6500/7511]\n",
      "loss: 2.01419425138738e-06  [7000/7511]\n",
      "loss: 1.1123244121336029e-06  [7500/7511]\n",
      "Test Error: Avg loss: 4.1167009615863995e-06 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.5802671669007395e-06  [0/7511]\n",
      "loss: 1.0199343591921206e-07  [500/7511]\n",
      "loss: 3.969001227233093e-06  [1000/7511]\n",
      "loss: 9.972022780857515e-07  [1500/7511]\n",
      "loss: 1.291156195293297e-06  [2000/7511]\n",
      "loss: 1.6654229284540634e-07  [2500/7511]\n",
      "loss: 4.636552603187738e-06  [3000/7511]\n",
      "loss: 2.9428906600514892e-06  [3500/7511]\n",
      "loss: 1.2717663366856868e-06  [4000/7511]\n",
      "loss: 1.1403634744056035e-05  [4500/7511]\n",
      "loss: 1.0057790404971456e-06  [5000/7511]\n",
      "loss: 1.1270344657532405e-06  [5500/7511]\n",
      "loss: 1.1562978841084259e-07  [6000/7511]\n",
      "loss: 4.793299467564793e-06  [6500/7511]\n",
      "loss: 7.873996992202592e-07  [7000/7511]\n",
      "loss: 1.0675964290385309e-07  [7500/7511]\n",
      "Test Error: Avg loss: 3.93900065312532e-06 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.0078272794089571e-07  [0/7511]\n",
      "loss: 3.4437516660545953e-06  [500/7511]\n",
      "loss: 2.5823501914601366e-07  [1000/7511]\n",
      "loss: 8.580946655456501e-07  [1500/7511]\n",
      "loss: 7.825570946806693e-08  [2000/7511]\n",
      "loss: 9.05700119346875e-08  [2500/7511]\n",
      "loss: 1.4298969972514897e-06  [3000/7511]\n",
      "loss: 1.623434968678339e-06  [3500/7511]\n",
      "loss: 4.814721251023002e-06  [4000/7511]\n",
      "loss: 2.221842805738561e-06  [4500/7511]\n",
      "loss: 9.852435596258147e-07  [5000/7511]\n",
      "loss: 1.3470398130266403e-07  [5500/7511]\n",
      "loss: 4.879501830146182e-06  [6000/7511]\n",
      "loss: 7.118651978998969e-07  [6500/7511]\n",
      "loss: 6.408380954781023e-07  [7000/7511]\n",
      "loss: 1.0890266111118763e-07  [7500/7511]\n",
      "Test Error: Avg loss: 3.818665823863416e-06 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 3.4281681564607425e-06  [0/7511]\n",
      "loss: 1.563181513120071e-07  [500/7511]\n",
      "loss: 2.096923026329023e-06  [1000/7511]\n",
      "loss: 8.27165933969809e-07  [1500/7511]\n",
      "loss: 1.0254871085635386e-06  [2000/7511]\n",
      "loss: 3.0763985705561936e-06  [2500/7511]\n",
      "loss: 1.2070388493157225e-06  [3000/7511]\n",
      "loss: 9.28941517486237e-06  [3500/7511]\n",
      "loss: 9.077903087018058e-07  [4000/7511]\n",
      "loss: 2.728688969000359e-06  [4500/7511]\n",
      "loss: 3.285384764240007e-06  [5000/7511]\n",
      "loss: 2.4921248495957116e-06  [5500/7511]\n",
      "loss: 4.805908702110173e-07  [6000/7511]\n",
      "loss: 4.7099564426389406e-07  [6500/7511]\n",
      "loss: 2.4122120976244332e-06  [7000/7511]\n",
      "loss: 3.4340307593083708e-06  [7500/7511]\n",
      "Test Error: Avg loss: 3.6773973666386253e-06 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.4750381751582609e-06  [0/7511]\n",
      "loss: 1.4943245219001255e-07  [500/7511]\n",
      "loss: 7.33913975636824e-06  [1000/7511]\n",
      "loss: 3.285334059910383e-06  [1500/7511]\n",
      "loss: 1.9927711036871187e-06  [2000/7511]\n",
      "loss: 2.2707085918227676e-06  [2500/7511]\n",
      "loss: 3.6890830870106583e-06  [3000/7511]\n",
      "loss: 2.679092631296953e-06  [3500/7511]\n",
      "loss: 8.932365602731807e-08  [4000/7511]\n",
      "loss: 3.300682237750152e-06  [4500/7511]\n",
      "loss: 2.6271472961525433e-06  [5000/7511]\n",
      "loss: 5.9572748511982354e-08  [5500/7511]\n",
      "loss: 6.257102995732566e-07  [6000/7511]\n",
      "loss: 2.0965487692592433e-06  [6500/7511]\n",
      "loss: 1.7254347994821728e-06  [7000/7511]\n",
      "loss: 1.7398306226823479e-06  [7500/7511]\n",
      "Test Error: Avg loss: 3.536660846781695e-06 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 4.1676312889649125e-07  [0/7511]\n",
      "loss: 6.534856993312133e-07  [500/7511]\n",
      "loss: 1.0592393806518885e-07  [1000/7511]\n",
      "loss: 4.789517333847471e-06  [1500/7511]\n",
      "loss: 9.787793260329636e-07  [2000/7511]\n",
      "loss: 4.4182884266774636e-06  [2500/7511]\n",
      "loss: 2.1600499167107046e-06  [3000/7511]\n",
      "loss: 1.5300157656383817e-06  [3500/7511]\n",
      "loss: 2.3204977424029494e-06  [4000/7511]\n",
      "loss: 3.1680108349974034e-06  [4500/7511]\n",
      "loss: 9.317768672190141e-07  [5000/7511]\n",
      "loss: 1.5176208023603976e-07  [5500/7511]\n",
      "loss: 6.486061465693638e-07  [6000/7511]\n",
      "loss: 4.600287084599586e-08  [6500/7511]\n",
      "loss: 5.83834321332688e-07  [7000/7511]\n",
      "loss: 1.7753154679667205e-07  [7500/7511]\n",
      "Test Error: Avg loss: 3.3860909076988753e-06 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 2.027998789344565e-06  [0/7511]\n",
      "loss: 7.460753863597347e-07  [500/7511]\n",
      "loss: 1.4302842146207695e-06  [1000/7511]\n",
      "loss: 7.872075116210908e-07  [1500/7511]\n",
      "loss: 1.7145473520940868e-06  [2000/7511]\n",
      "loss: 7.749554242764134e-07  [2500/7511]\n",
      "loss: 1.816864369175164e-06  [3000/7511]\n",
      "loss: 7.830876143088972e-07  [3500/7511]\n",
      "loss: 2.2674330466543324e-06  [4000/7511]\n",
      "loss: 7.446409995282011e-07  [4500/7511]\n",
      "loss: 5.954101652605459e-06  [5000/7511]\n",
      "loss: 2.0309034880483523e-06  [5500/7511]\n",
      "loss: 6.20963930941798e-07  [6000/7511]\n",
      "loss: 5.009304118175351e-07  [6500/7511]\n",
      "loss: 6.048244358680677e-07  [7000/7511]\n",
      "loss: 1.1170131841709008e-07  [7500/7511]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: Avg loss: 3.227148685586329e-06 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 4.5425062467074895e-07  [0/7511]\n",
      "loss: 6.114819370850455e-07  [500/7511]\n",
      "loss: 3.589718744478887e-07  [1000/7511]\n",
      "loss: 4.429116131632327e-07  [1500/7511]\n",
      "loss: 2.8383028620737605e-06  [2000/7511]\n",
      "loss: 4.248506684234599e-06  [2500/7511]\n",
      "loss: 7.824251042620745e-07  [3000/7511]\n",
      "loss: 1.4578512264051824e-06  [3500/7511]\n",
      "loss: 2.452104581607273e-06  [4000/7511]\n",
      "loss: 2.474247366990312e-06  [4500/7511]\n",
      "loss: 1.1983579497609753e-06  [5000/7511]\n",
      "loss: 8.731848311072099e-08  [5500/7511]\n",
      "loss: 8.788616128185822e-07  [6000/7511]\n",
      "loss: 3.69525139376492e-07  [6500/7511]\n",
      "loss: 1.1111561093457567e-07  [7000/7511]\n",
      "loss: 4.549098093775683e-07  [7500/7511]\n",
      "Test Error: Avg loss: 3.138438196533762e-06 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 8.584222541685449e-07  [0/7511]\n",
      "loss: 3.777168728902325e-07  [500/7511]\n",
      "loss: 9.241132374882e-07  [1000/7511]\n",
      "loss: 7.537892088294029e-07  [1500/7511]\n",
      "loss: 3.0264732231444214e-07  [2000/7511]\n",
      "loss: 1.8892077378040995e-06  [2500/7511]\n",
      "loss: 6.471233291449607e-07  [3000/7511]\n",
      "loss: 1.6065336012616172e-06  [3500/7511]\n",
      "loss: 3.254624289183994e-06  [4000/7511]\n",
      "loss: 4.661941147787729e-06  [4500/7511]\n",
      "loss: 9.034897061610536e-07  [5000/7511]\n",
      "loss: 2.1999132115979592e-07  [5500/7511]\n",
      "loss: 3.5317552828928456e-06  [6000/7511]\n",
      "loss: 5.423915354185738e-06  [6500/7511]\n",
      "loss: 2.7535620574781206e-06  [7000/7511]\n",
      "loss: 6.307499234026182e-08  [7500/7511]\n",
      "Test Error: Avg loss: 3.0113601308567815e-06 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.00014747180102858692  [0/7511]\n",
      "loss: 1.0303210729034618e-07  [500/7511]\n",
      "loss: 4.202334196179436e-07  [1000/7511]\n",
      "loss: 1.8621509525473812e-06  [1500/7511]\n",
      "loss: 1.9962803889939096e-06  [2000/7511]\n",
      "loss: 2.1990074401401216e-06  [2500/7511]\n",
      "loss: 4.798190502697253e-07  [3000/7511]\n",
      "loss: 4.37151470578101e-07  [3500/7511]\n",
      "loss: 3.415052844957245e-07  [4000/7511]\n",
      "loss: 2.110863022153353e-07  [4500/7511]\n",
      "loss: 1.051685444508621e-06  [5000/7511]\n",
      "loss: 4.434114941886946e-08  [5500/7511]\n",
      "loss: 2.2110709778644377e-06  [6000/7511]\n",
      "loss: 3.564757946605823e-07  [6500/7511]\n",
      "loss: 2.2236499717109837e-06  [7000/7511]\n",
      "loss: 8.908907034310687e-08  [7500/7511]\n",
      "Test Error: Avg loss: 2.8648300056335188e-06 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 1.8473676846042508e-06  [0/7511]\n",
      "loss: 1.7912643670570105e-06  [500/7511]\n",
      "loss: 1.2324044007527846e-07  [1000/7511]\n",
      "loss: 9.034689441023147e-08  [1500/7511]\n",
      "loss: 1.0172632300964324e-06  [2000/7511]\n",
      "loss: 1.731895480361345e-07  [2500/7511]\n",
      "loss: 1.530939016447519e-06  [3000/7511]\n",
      "loss: 3.680217162127519e-07  [3500/7511]\n",
      "loss: 3.758031425604713e-06  [4000/7511]\n",
      "loss: 1.5225489846670826e-07  [4500/7511]\n",
      "loss: 2.0502093320828862e-06  [5000/7511]\n",
      "loss: 5.621890295515186e-07  [5500/7511]\n",
      "loss: 1.479881120758364e-05  [6000/7511]\n",
      "loss: 8.055131911532953e-05  [6500/7511]\n",
      "loss: 6.053713264009275e-07  [7000/7511]\n",
      "loss: 9.565833352098707e-07  [7500/7511]\n",
      "Test Error: Avg loss: 2.8103563583180288e-06 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 1.7505556115793297e-07  [0/7511]\n",
      "loss: 1.8733838942353032e-06  [500/7511]\n",
      "loss: 5.125432949171227e-07  [1000/7511]\n",
      "loss: 4.1751872004169854e-07  [1500/7511]\n",
      "loss: 2.9901043490099255e-06  [2000/7511]\n",
      "loss: 2.390518147876719e-07  [2500/7511]\n",
      "loss: 2.930544496848597e-06  [3000/7511]\n",
      "loss: 1.2518536607331043e-07  [3500/7511]\n",
      "loss: 2.1895651514114434e-07  [4000/7511]\n",
      "loss: 2.087775555992266e-06  [4500/7511]\n",
      "loss: 2.747705991623661e-07  [5000/7511]\n",
      "loss: 4.438145424501272e-07  [5500/7511]\n",
      "loss: 1.853329990808561e-06  [6000/7511]\n",
      "loss: 1.1013020184691413e-06  [6500/7511]\n",
      "loss: 1.4849896388113848e-06  [7000/7511]\n",
      "loss: 2.766073805560154e-07  [7500/7511]\n",
      "Test Error: Avg loss: 2.7109119658595977e-06 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 4.36770051237545e-06  [0/7511]\n",
      "loss: 3.1368288091471186e-06  [500/7511]\n",
      "loss: 1.634177351661492e-05  [1000/7511]\n",
      "loss: 2.962117378046969e-07  [1500/7511]\n",
      "loss: 3.1802958346816013e-06  [2000/7511]\n",
      "loss: 1.383211696293074e-07  [2500/7511]\n",
      "loss: 9.141307600657456e-06  [3000/7511]\n",
      "loss: 2.1652060411270213e-07  [3500/7511]\n",
      "loss: 2.3648048852464854e-07  [4000/7511]\n",
      "loss: 2.8005292307398122e-08  [4500/7511]\n",
      "loss: 4.3228430968156317e-07  [5000/7511]\n",
      "loss: 1.8481907204659365e-07  [5500/7511]\n",
      "loss: 3.494931775094301e-07  [6000/7511]\n",
      "loss: 3.525129557147011e-07  [6500/7511]\n",
      "loss: 3.124413012756122e-07  [7000/7511]\n",
      "loss: 2.712292825890472e-07  [7500/7511]\n",
      "Test Error: Avg loss: 2.6201747708507625e-06 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 9.307333925789862e-07  [0/7511]\n",
      "loss: 3.518396169965854e-07  [500/7511]\n",
      "loss: 1.3748949641012587e-06  [1000/7511]\n",
      "loss: 8.48743084702619e-08  [1500/7511]\n",
      "loss: 1.347815299368449e-07  [2000/7511]\n",
      "loss: 3.3602125881770917e-07  [2500/7511]\n",
      "loss: 8.147064818331273e-07  [3000/7511]\n",
      "loss: 1.86993460715712e-07  [3500/7511]\n",
      "loss: 8.203292622965819e-08  [4000/7511]\n",
      "loss: 4.4901076989845023e-07  [4500/7511]\n",
      "loss: 8.332467587024439e-07  [5000/7511]\n",
      "loss: 1.506638227510848e-06  [5500/7511]\n",
      "loss: 4.739845849144331e-08  [6000/7511]\n",
      "loss: 9.400508815815556e-08  [6500/7511]\n",
      "loss: 3.042862033453275e-07  [7000/7511]\n",
      "loss: 3.7520669593504863e-07  [7500/7511]\n",
      "Test Error: Avg loss: 2.561571894974055e-06 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 1.3852645679435227e-06  [0/7511]\n",
      "loss: 6.040514790583984e-07  [500/7511]\n",
      "loss: 2.395867113591521e-07  [1000/7511]\n",
      "loss: 2.1943698413906532e-07  [1500/7511]\n",
      "loss: 5.151304094397346e-07  [2000/7511]\n",
      "loss: 2.3706427043634903e-07  [2500/7511]\n",
      "loss: 4.42148007095966e-07  [3000/7511]\n",
      "loss: 1.2566334817165625e-07  [3500/7511]\n",
      "loss: 1.7979533595280373e-07  [4000/7511]\n",
      "loss: 7.356567834904126e-07  [4500/7511]\n",
      "loss: 1.2622527378880477e-07  [5000/7511]\n",
      "loss: 1.2585252306962502e-07  [5500/7511]\n",
      "loss: 9.856348981429619e-08  [6000/7511]\n",
      "loss: 5.825256153002556e-07  [6500/7511]\n",
      "loss: 2.6807651920535136e-07  [7000/7511]\n",
      "loss: 1.8298077009148983e-07  [7500/7511]\n",
      "Test Error: Avg loss: 2.469048075218177e-06 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 1.0604316003082204e-06  [0/7511]\n",
      "loss: 1.9709379728283238e-07  [500/7511]\n",
      "loss: 2.327155357306765e-07  [1000/7511]\n",
      "loss: 1.2942238072355394e-06  [1500/7511]\n",
      "loss: 2.976818223032751e-07  [2000/7511]\n",
      "loss: 8.949342031883134e-07  [2500/7511]\n",
      "loss: 2.0171840731109114e-07  [3000/7511]\n",
      "loss: 2.203028998337686e-06  [3500/7511]\n",
      "loss: 3.322039390241116e-07  [4000/7511]\n",
      "loss: 3.7660183238585887e-07  [4500/7511]\n",
      "loss: 3.5734465200221166e-06  [5000/7511]\n",
      "loss: 1.9041341658976307e-07  [5500/7511]\n",
      "loss: 2.677747090729099e-07  [6000/7511]\n",
      "loss: 1.4607948628508893e-07  [6500/7511]\n",
      "loss: 1.33799332502349e-07  [7000/7511]\n",
      "loss: 1.4362917966082023e-07  [7500/7511]\n",
      "Test Error: Avg loss: 2.4044991591432994e-06 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 3.948790435970295e-06  [0/7511]\n",
      "loss: 5.928093571583304e-08  [500/7511]\n",
      "loss: 5.323109348864818e-07  [1000/7511]\n",
      "loss: 5.082881671114592e-07  [1500/7511]\n",
      "loss: 8.297899967146805e-07  [2000/7511]\n",
      "loss: 2.0539170009215013e-07  [2500/7511]\n",
      "loss: 3.882631460783159e-07  [3000/7511]\n",
      "loss: 1.2811540273105493e-07  [3500/7511]\n",
      "loss: 1.6515105016878806e-07  [4000/7511]\n",
      "loss: 7.81963024110155e-07  [4500/7511]\n",
      "loss: 2.2397229315629374e-07  [5000/7511]\n",
      "loss: 5.627113637274306e-07  [5500/7511]\n",
      "loss: 7.712787919444963e-07  [6000/7511]\n",
      "loss: 2.2536366941494634e-06  [6500/7511]\n",
      "loss: 2.009543464964736e-07  [7000/7511]\n",
      "loss: 2.5386012225681043e-07  [7500/7511]\n",
      "Test Error: Avg loss: 2.342266074859076e-06 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 1.1816220535365574e-07  [0/7511]\n",
      "loss: 1.0520113846723689e-06  [500/7511]\n",
      "loss: 4.556170551950345e-07  [1000/7511]\n",
      "loss: 3.176233349222457e-06  [1500/7511]\n",
      "loss: 8.010430008198455e-08  [2000/7511]\n",
      "loss: 2.5988206289184745e-06  [2500/7511]\n",
      "loss: 2.937365707111894e-06  [3000/7511]\n",
      "loss: 2.6016797960437543e-07  [3500/7511]\n",
      "loss: 2.5099180334109406e-07  [4000/7511]\n",
      "loss: 3.590729136249138e-07  [4500/7511]\n",
      "loss: 5.394537652136933e-07  [5000/7511]\n",
      "loss: 1.1081800010970255e-07  [5500/7511]\n",
      "loss: 4.7439596073672874e-07  [6000/7511]\n",
      "loss: 3.0880514145792404e-07  [6500/7511]\n",
      "loss: 2.083152708109992e-07  [7000/7511]\n",
      "loss: 1.374892804051342e-07  [7500/7511]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: Avg loss: 2.3018707876996403e-06 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 2.0069852268989052e-07  [0/7511]\n",
      "loss: 8.352332088179537e-07  [500/7511]\n",
      "loss: 1.4336268350234604e-07  [1000/7511]\n",
      "loss: 1.9781614923886082e-07  [1500/7511]\n",
      "loss: 1.3698008842766285e-06  [2000/7511]\n",
      "loss: 3.5461960123939207e-06  [2500/7511]\n",
      "loss: 8.727766385163704e-07  [3000/7511]\n",
      "loss: 5.322415290720528e-07  [3500/7511]\n",
      "loss: 5.139382324159669e-07  [4000/7511]\n",
      "loss: 1.0305306119562374e-07  [4500/7511]\n",
      "loss: 1.1403089672512579e-07  [5000/7511]\n",
      "loss: 1.9670936524107674e-07  [5500/7511]\n",
      "loss: 1.3925675546033744e-07  [6000/7511]\n",
      "loss: 2.0155330560100992e-07  [6500/7511]\n",
      "loss: 8.841123531055928e-07  [7000/7511]\n",
      "loss: 1.6845323216330144e-06  [7500/7511]\n",
      "Test Error: Avg loss: 2.265897747346356e-06 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 4.318594903907069e-07  [0/7511]\n",
      "loss: 2.2658720411072863e-07  [500/7511]\n",
      "loss: 1.903474498021751e-07  [1000/7511]\n",
      "loss: 1.3928477926583582e-07  [1500/7511]\n",
      "loss: 2.7297767246636795e-07  [2000/7511]\n",
      "loss: 1.0010123787651537e-06  [2500/7511]\n",
      "loss: 5.770476150246395e-07  [3000/7511]\n",
      "loss: 2.66090046352474e-06  [3500/7511]\n",
      "loss: 2.1134833616542892e-07  [4000/7511]\n",
      "loss: 8.538656857126625e-07  [4500/7511]\n",
      "loss: 5.802693863188324e-07  [5000/7511]\n",
      "loss: 1.674976175536358e-07  [5500/7511]\n",
      "loss: 1.9903808379240218e-07  [6000/7511]\n",
      "loss: 6.59575363215481e-08  [6500/7511]\n",
      "loss: 8.393435280140693e-08  [7000/7511]\n",
      "loss: 2.3769226231706853e-07  [7500/7511]\n",
      "Test Error: Avg loss: 2.2232113757826017e-06 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 1.426144251581718e-07  [0/7511]\n",
      "loss: 1.9444462395767914e-07  [500/7511]\n",
      "loss: 9.387262878135516e-08  [1000/7511]\n",
      "loss: 2.2230977947401698e-07  [1500/7511]\n",
      "loss: 2.720168595260475e-06  [2000/7511]\n",
      "loss: 1.1526351784141298e-07  [2500/7511]\n",
      "loss: 1.6961809023996466e-07  [3000/7511]\n",
      "loss: 1.0680571449483978e-06  [3500/7511]\n",
      "loss: 5.774581381956523e-07  [4000/7511]\n",
      "loss: 2.0763616248586914e-07  [4500/7511]\n",
      "loss: 3.060278288558038e-07  [5000/7511]\n",
      "loss: 5.6418958394033325e-08  [5500/7511]\n",
      "loss: 1.32375441808108e-06  [6000/7511]\n",
      "loss: 8.047501864894002e-07  [6500/7511]\n",
      "loss: 2.808181704949675e-07  [7000/7511]\n",
      "loss: 1.1739828096324345e-06  [7500/7511]\n",
      "Test Error: Avg loss: 2.188986943128258e-06 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 5.196828922748864e-08  [0/7511]\n",
      "loss: 5.354401082513505e-07  [500/7511]\n",
      "loss: 3.0262133350333897e-06  [1000/7511]\n",
      "loss: 2.97330046805655e-07  [1500/7511]\n",
      "loss: 1.800963218556717e-07  [2000/7511]\n",
      "loss: 1.7292764198373334e-07  [2500/7511]\n",
      "loss: 5.322898743997939e-08  [3000/7511]\n",
      "loss: 3.2554370932302845e-07  [3500/7511]\n",
      "loss: 1.2686067748290952e-05  [4000/7511]\n",
      "loss: 2.0297207470321155e-07  [4500/7511]\n",
      "loss: 2.409310582152102e-06  [5000/7511]\n",
      "loss: 9.781516041584837e-08  [5500/7511]\n",
      "loss: 1.4736465345777106e-06  [6000/7511]\n",
      "loss: 1.1694757517943799e-07  [6500/7511]\n",
      "loss: 3.086227025050903e-07  [7000/7511]\n",
      "loss: 1.3926646147410793e-07  [7500/7511]\n",
      "Test Error: Avg loss: 2.166075602619536e-06 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 2.4959810218661005e-08  [0/7511]\n",
      "loss: 1.314222259907183e-07  [500/7511]\n",
      "loss: 5.445467650133651e-07  [1000/7511]\n",
      "loss: 1.4747188004093914e-07  [1500/7511]\n",
      "loss: 2.465744444180018e-07  [2000/7511]\n",
      "loss: 7.575727067887783e-08  [2500/7511]\n",
      "loss: 2.930239020315639e-07  [3000/7511]\n",
      "loss: 1.3473930948748603e-07  [3500/7511]\n",
      "loss: 1.521241728141831e-07  [4000/7511]\n",
      "loss: 8.388443575313431e-07  [4500/7511]\n",
      "loss: 8.198383056878811e-07  [5000/7511]\n",
      "loss: 1.8877422292007395e-07  [5500/7511]\n",
      "loss: 4.20685324797887e-07  [6000/7511]\n",
      "loss: 2.8075859859200136e-07  [6500/7511]\n",
      "loss: 6.752279801958139e-08  [7000/7511]\n",
      "loss: 2.0469478840823285e-06  [7500/7511]\n",
      "Test Error: Avg loss: 2.1100710074400504e-06 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 2.2002186028657889e-07  [0/7511]\n",
      "loss: 2.8031530519001535e-07  [500/7511]\n",
      "loss: 2.2958643342008145e-07  [1000/7511]\n",
      "loss: 2.1468633804033743e-07  [1500/7511]\n",
      "loss: 2.710272610784159e-07  [2000/7511]\n",
      "loss: 3.050042209906678e-07  [2500/7511]\n",
      "loss: 1.9716521819646005e-06  [3000/7511]\n",
      "loss: 5.03720411870745e-06  [3500/7511]\n",
      "loss: 2.1674433980933827e-07  [4000/7511]\n",
      "loss: 3.0805861683802505e-07  [4500/7511]\n",
      "loss: 8.343123170106992e-08  [5000/7511]\n",
      "loss: 1.6277168413125764e-07  [5500/7511]\n",
      "loss: 4.132747619678412e-07  [6000/7511]\n",
      "loss: 6.864300416964397e-08  [6500/7511]\n",
      "loss: 1.0546970941049949e-07  [7000/7511]\n",
      "loss: 3.360484924996854e-06  [7500/7511]\n",
      "Test Error: Avg loss: 2.0661438008777083e-06 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 1.5601847280777292e-07  [0/7511]\n",
      "loss: 2.608009026516811e-07  [500/7511]\n",
      "loss: 4.366765722352284e-07  [1000/7511]\n",
      "loss: 2.2213149009076005e-07  [1500/7511]\n",
      "loss: 1.3840634949247033e-07  [2000/7511]\n",
      "loss: 3.202424522896763e-06  [2500/7511]\n",
      "loss: 5.564527683077358e-08  [3000/7511]\n",
      "loss: 3.309912131044257e-07  [3500/7511]\n",
      "loss: 8.822873382996477e-07  [4000/7511]\n",
      "loss: 1.2844444427173585e-05  [4500/7511]\n",
      "loss: 5.502083411101921e-08  [5000/7511]\n",
      "loss: 8.927921868462363e-08  [5500/7511]\n",
      "loss: 1.2928001524414867e-05  [6000/7511]\n",
      "loss: 1.2006847782686236e-06  [6500/7511]\n",
      "loss: 1.9715650978469057e-07  [7000/7511]\n",
      "loss: 1.637552315969515e-07  [7500/7511]\n",
      "Test Error: Avg loss: 2.0438937999773215e-06 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# executing training and testing\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_ldr, model, loss_fn, optimizer)\n",
    "    test_loop(test_ldr, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First NN model\n",
    "# network architecture\n",
    "# class NeuralNetwork(torch.nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(NeuralNetwork, self).__init__()\n",
    "#         self.linear_relu_stack = torch.nn.Sequential(\n",
    "#             torch.nn.Linear(82, 30),\n",
    "#             torch.nn.ReLU(),\n",
    "#             torch.nn.Linear(30, 30),\n",
    "#             torch.nn.ReLU(),\n",
    "#             torch.nn.Linear(30, 1),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         pred_conc = self.linear_relu_stack(x)\n",
    "#         return pred_conc"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
