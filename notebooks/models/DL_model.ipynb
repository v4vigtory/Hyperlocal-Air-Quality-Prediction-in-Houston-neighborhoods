{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 160,
=======
   "execution_count": 57,
   "id": "c9002b73",
>>>>>>> ba920bf3302ab53c98e7a1cce9c3825755fed9cf
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import basic python packages for data analysis and plotting\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import matplotlib.lines as mlines\n",
    "import pylab as plot\n",
    "import matplotlib\n",
    "import random\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "metadata": {},
   "source": [
    "## Pytorch practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: [1. 1. 1. 1. 1.]\n",
      "t: tensor([2., 2., 2., 2., 2.])\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "data = [[1, 2],[3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "x_data\n",
    "\n",
    "shape = (2,3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "rand_tensor\n",
    "\n",
    "tensor = torch.ones(4, 4)\n",
    "tensor.shape\n",
    "\n",
    "t1 = torch.cat([tensor, tensor, tensor], dim=-2)\n",
    "\n",
    "t = torch.ones(5)\n",
    "t\n",
    "\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")\n",
    "\n",
    "t.add_(1)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.sum()"
   ]
  },
  {
   "cell_type": "markdown",
=======
   "id": "35868766",
>>>>>>> ba920bf3302ab53c98e7a1cce9c3825755fed9cf
   "metadata": {},
   "source": [
    "## (A) Dataset prep"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 220,
=======
   "execution_count": 60,
   "id": "091fbf7d",
>>>>>>> ba920bf3302ab53c98e7a1cce9c3825755fed9cf
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all datasets to create master_df\n",
    "\n",
    "root = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "\n",
    "df_aq = pd.read_csv(root + \"/data/cleaned/air_quality_NO2.csv\", index_col=0)[['value','latitude', 'longitude']]\n",
    "df_met = pd.read_csv(root + \"/data/cleaned/nO2_met.csv\", index_col=0)\n",
    "df_fac = pd.read_csv(root + \"/data/cleaned/no2_fac_data.csv\", index_col=0)\n",
    "# df_fac.drop(df_fac.columns[df_fac.columns.str.contains('_emsdist')], axis=1, inplace=True)\n",
    "df_traffic = pd.read_csv(root + \"/data/cleaned/intersection_final.csv\", index_col=0)\n",
    "\n",
    "df_m1 = df_aq.merge(df_met, on = ['latitude', 'longitude'], how = 'inner')\n",
    "df_m2 = df_m1.merge(df_fac, on = ['latitude', 'longitude'], how = 'inner')\n",
    "df_merged = df_m2.merge(df_traffic, on = ['latitude', 'longitude'], how = 'inner')\n",
    "df_merged.drop(columns = ['latitude', 'longitude'], inplace=True)\n",
    "\n",
    "X = df_merged.drop(\"value\",1) \n",
    "y = df_merged[\"value\"]\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to scale and transform input data\n",
    "# def get_data(X, y):\n",
    "#     X = X.values\n",
    "#     y = y.values\n",
    "#     # scaling the data\n",
    "#     feature_scaler = StandardScaler()\n",
    "#     X = feature_scaler.fit_transform(X)\n",
    "#     return X, y\n",
    "\n",
    "# # acquiring transformed data\n",
    "# X_arr, y_arr = get_data(X, y)\n",
    "\n",
    "# # splitting into test and train\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_arr, y_arr, test_size=0.3)\n",
    "# cols = np.array(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
=======
   "execution_count": 62,
   "id": "c2ced158",
>>>>>>> ba920bf3302ab53c98e7a1cce9c3825755fed9cf
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting into test and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(X), np.array(y), test_size=0.3)\n",
    "cols = np.array(X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a03e77",
   "metadata": {},
   "source": [
    "## (B) Modeling"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 223,
=======
   "execution_count": 69,
   "id": "54e71ff2",
>>>>>>> ba920bf3302ab53c98e7a1cce9c3825755fed9cf
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset class for feeding in data\n",
    "class AirQualityDataset(torch.utils.data.Dataset):\n",
    "\n",
    "  def __init__(self, X_arr, y_arr):\n",
    "    self.x_data = torch.tensor(X_arr, \\\n",
    "      dtype=torch.float32)\n",
    "    self.y_data = torch.tensor(y_arr, \\\n",
    "      dtype=torch.float32)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.x_data)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    preds = self.x_data[idx,:]  # or just [idx]\n",
    "    conc = self.y_data[idx] \n",
    "    return (preds, conc)       # tuple of matrices\n",
    "\n",
    "# prepping data for training\n",
    "batch_size = 5\n",
    "train_ds = AirQualityDataset(X_train, y_train)\n",
    "test_ds = AirQualityDataset(X_test, y_test)\n",
    "train_ldr = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "test_ldr = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 224,
=======
   "execution_count": 71,
   "id": "4b87350e",
>>>>>>> ba920bf3302ab53c98e7a1cce9c3825755fed9cf
   "metadata": {},
   "outputs": [],
   "source": [
    "# network architecture\n",
    "class NeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.linear_tanh_stack = torch.nn.Sequential(\n",
    "            torch.nn.Linear(82, 60),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(60, 60),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(60, 40),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(40, 30),\n",
    "            torch.nn.Tanh(),\n",
    "#             torch.nn.Dropout(p=0.1),\n",
    "            torch.nn.Linear(30, 20),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(20, 20),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(20,10),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(10, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        pred_conc = self.linear_tanh_stack(x)\n",
    "        return pred_conc"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 225,
=======
   "execution_count": 72,
   "id": "15fc1c95",
>>>>>>> ba920bf3302ab53c98e7a1cce9c3825755fed9cf
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (linear_tanh_stack): Sequential(\n",
      "    (0): Linear(in_features=82, out_features=60, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=60, out_features=60, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=60, out_features=40, bias=True)\n",
      "    (5): Tanh()\n",
      "    (6): Linear(in_features=40, out_features=30, bias=True)\n",
      "    (7): Tanh()\n",
      "    (8): Linear(in_features=30, out_features=20, bias=True)\n",
      "    (9): Tanh()\n",
      "    (10): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (11): Tanh()\n",
      "    (12): Linear(in_features=20, out_features=10, bias=True)\n",
      "    (13): Tanh()\n",
      "    (14): Linear(in_features=10, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Layer: linear_tanh_stack.0.weight | Size: torch.Size([60, 82]) | Values : tensor([[ 0.0129, -0.0951, -0.0156, -0.0907, -0.0515, -0.0283,  0.0413, -0.0402,\n",
      "          0.0513, -0.0336,  0.0555, -0.0924, -0.0916, -0.0915, -0.0960, -0.0936,\n",
      "          0.0932, -0.0157, -0.0591,  0.0595, -0.0378, -0.0898,  0.0631,  0.0475,\n",
      "          0.0925, -0.0453,  0.0888, -0.0927, -0.0039, -0.0868,  0.0387, -0.0028,\n",
      "          0.0232, -0.0377,  0.1056,  0.0497, -0.0328, -0.1000,  0.0859, -0.0363,\n",
      "          0.0484,  0.0741, -0.0702,  0.0989,  0.1041, -0.0260, -0.1087, -0.0630,\n",
      "         -0.0914, -0.0791,  0.0914, -0.1040,  0.0600, -0.0059, -0.0926, -0.0946,\n",
      "          0.0682,  0.0420,  0.0661, -0.0122, -0.0987, -0.1031,  0.0762,  0.0640,\n",
      "         -0.0899,  0.0823,  0.0609,  0.0629, -0.0451, -0.0716, -0.1014,  0.0929,\n",
      "         -0.0799,  0.0744, -0.1026, -0.0396,  0.0327,  0.0886,  0.0943,  0.0952,\n",
      "          0.0443, -0.0546],\n",
      "        [ 0.0714,  0.0612, -0.1065, -0.0515,  0.0145, -0.0068, -0.0091,  0.0677,\n",
      "          0.0977,  0.0104,  0.0260,  0.1087, -0.0082,  0.0861, -0.0940, -0.0899,\n",
      "          0.0319, -0.0590, -0.1088,  0.0969, -0.0512,  0.0603, -0.0708, -0.0921,\n",
      "          0.0597,  0.0828,  0.0801, -0.0959, -0.0211,  0.1059, -0.0111,  0.0729,\n",
      "         -0.0107, -0.0654,  0.0085,  0.0794,  0.0546, -0.0313, -0.0538, -0.0268,\n",
      "         -0.0862, -0.0832,  0.0165,  0.0352, -0.0919,  0.0017,  0.0579, -0.0827,\n",
      "         -0.1057, -0.0956,  0.0062,  0.0062,  0.0405,  0.0077, -0.0120,  0.0042,\n",
      "         -0.0785, -0.0604,  0.0183, -0.0944, -0.0116,  0.0270,  0.0641,  0.0470,\n",
      "          0.0915, -0.0072, -0.0495,  0.1091,  0.0198,  0.0986,  0.0828,  0.0524,\n",
      "          0.0863,  0.0547, -0.0716, -0.0767, -0.1034, -0.0708, -0.0366,  0.0316,\n",
      "          0.0533,  0.0979]], grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_tanh_stack.0.bias | Size: torch.Size([60]) | Values : tensor([ 0.0721, -0.0912], grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_tanh_stack.2.weight | Size: torch.Size([60, 60]) | Values : tensor([[ 0.0711,  0.1273, -0.0515,  0.1114,  0.0073, -0.1001, -0.0738,  0.0495,\n",
      "          0.1041,  0.1043,  0.0230,  0.0801, -0.0094, -0.1018,  0.0698, -0.0032,\n",
      "         -0.1198, -0.1153, -0.0663, -0.0688,  0.0922,  0.0729, -0.0454,  0.0517,\n",
      "         -0.0394,  0.0471, -0.0068,  0.0011, -0.1125,  0.1224,  0.0770,  0.0628,\n",
      "          0.0408, -0.0834, -0.0732, -0.0794,  0.0881,  0.1225,  0.0512,  0.0644,\n",
      "         -0.0911,  0.0126,  0.0979,  0.1276, -0.0806,  0.0263,  0.0714, -0.0331,\n",
      "         -0.0880, -0.1077,  0.1077, -0.0602, -0.0621,  0.0250,  0.0167, -0.0810,\n",
      "         -0.0971, -0.1167, -0.0606, -0.0916],\n",
      "        [-0.1148, -0.0028,  0.0444, -0.0974,  0.1214, -0.0751, -0.0883,  0.1259,\n",
      "         -0.0085, -0.0033, -0.0240,  0.0505, -0.0067, -0.0028,  0.1268,  0.0704,\n",
      "          0.0928, -0.0984, -0.0069, -0.0532, -0.1032,  0.0302,  0.0560, -0.0671,\n",
      "         -0.0541, -0.0547,  0.0272, -0.0012, -0.0245, -0.0221, -0.0997,  0.0668,\n",
      "         -0.1190,  0.0437, -0.0445, -0.0944, -0.0237, -0.0245, -0.0370,  0.0914,\n",
      "          0.1147, -0.0448,  0.0065,  0.0961, -0.0051,  0.0447, -0.0973, -0.0868,\n",
      "         -0.0782, -0.0028, -0.0045,  0.0550, -0.0663,  0.0100,  0.0995, -0.0588,\n",
      "          0.1157,  0.0787,  0.0476,  0.0798]], grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_tanh_stack.2.bias | Size: torch.Size([60]) | Values : tensor([-0.1209,  0.0422], grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_tanh_stack.4.weight | Size: torch.Size([40, 60]) | Values : tensor([[ 0.1273,  0.0529,  0.1188,  0.0835,  0.0978,  0.1172, -0.0089,  0.1141,\n",
      "          0.0389,  0.0884, -0.1090,  0.0880,  0.1056, -0.0698,  0.0993, -0.0954,\n",
      "          0.0564,  0.0432,  0.1049, -0.0421, -0.0378, -0.0037, -0.0963, -0.0479,\n",
      "          0.1176,  0.0104,  0.0928,  0.0586,  0.0836, -0.0315, -0.0831, -0.1150,\n",
      "          0.0526,  0.0147,  0.0642,  0.0639, -0.0914, -0.0557, -0.0498,  0.0305,\n",
      "          0.0013, -0.0814, -0.1218, -0.0921,  0.0352,  0.0703,  0.0536, -0.1214,\n",
      "         -0.0570,  0.0953,  0.0104,  0.0283, -0.1025,  0.0586,  0.0368,  0.1173,\n",
      "         -0.1071,  0.0878, -0.0917, -0.0168],\n",
      "        [ 0.0889,  0.0213, -0.0675,  0.0818,  0.1193,  0.0882,  0.1078, -0.0078,\n",
      "         -0.0365, -0.0990, -0.0303, -0.0899,  0.0878,  0.0661, -0.0668, -0.1281,\n",
      "         -0.0771,  0.0535, -0.0571, -0.0464,  0.0690, -0.0593, -0.0066, -0.0452,\n",
      "         -0.0413, -0.0664,  0.0052,  0.1085,  0.0659,  0.0119, -0.0855, -0.0140,\n",
      "         -0.0922, -0.1119, -0.0447,  0.1058, -0.0921,  0.0434, -0.0177, -0.1246,\n",
      "         -0.1125, -0.1271,  0.0925, -0.1051, -0.0622,  0.0325,  0.0611,  0.0629,\n",
      "         -0.0817,  0.0046, -0.0667,  0.0644,  0.0308,  0.0442,  0.0531,  0.0529,\n",
      "          0.0469, -0.0462,  0.0979, -0.0279]], grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_tanh_stack.4.bias | Size: torch.Size([40]) | Values : tensor([-0.0115,  0.0365], grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_tanh_stack.6.weight | Size: torch.Size([30, 40]) | Values : tensor([[ 0.0684,  0.0148,  0.0995, -0.0850,  0.1367, -0.0262,  0.0162,  0.1004,\n",
      "         -0.1490, -0.1192,  0.0117,  0.1523,  0.0565,  0.1397,  0.0141,  0.1322,\n",
      "          0.1307,  0.0923,  0.1258, -0.0329, -0.0842, -0.0047,  0.0198,  0.1039,\n",
      "         -0.0116, -0.0997,  0.0401, -0.0362, -0.0221, -0.1488, -0.0848, -0.0012,\n",
      "          0.1312,  0.0197, -0.0676, -0.0795,  0.0759,  0.0949,  0.0791,  0.1381],\n",
      "        [ 0.1257, -0.0667, -0.1295, -0.0598, -0.1362,  0.0184,  0.0658, -0.0139,\n",
      "          0.0621, -0.0277, -0.1231, -0.0064, -0.0668,  0.1192,  0.0784,  0.1287,\n",
      "          0.0829, -0.1292,  0.0422, -0.0589,  0.1501,  0.1087,  0.0100, -0.1414,\n",
      "         -0.0792,  0.0181, -0.0429, -0.1241, -0.0737, -0.0977,  0.1294,  0.0310,\n",
      "         -0.0619, -0.1125,  0.0954,  0.0946, -0.1383, -0.0094, -0.1049, -0.0099]],\n",
      "       grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_tanh_stack.6.bias | Size: torch.Size([30]) | Values : tensor([-0.1469,  0.1039], grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_tanh_stack.8.weight | Size: torch.Size([20, 30]) | Values : tensor([[ 0.1710, -0.0443, -0.1495,  0.1267, -0.0863, -0.1001, -0.0555, -0.0382,\n",
      "         -0.1203,  0.1279,  0.0256, -0.0358, -0.0521,  0.1215,  0.1794, -0.0161,\n",
      "          0.1309, -0.0282, -0.1380, -0.0320,  0.1372, -0.0826,  0.0911,  0.0817,\n",
      "         -0.1248,  0.1558,  0.0548,  0.0879,  0.0901,  0.1765],\n",
      "        [ 0.0477,  0.0852, -0.1513,  0.1129, -0.0818,  0.0586, -0.0679,  0.0381,\n",
      "         -0.1201,  0.0282,  0.0389, -0.0809,  0.0348, -0.1257,  0.1804,  0.1390,\n",
      "         -0.1078, -0.1456,  0.0359,  0.0144,  0.0361, -0.1468,  0.1069,  0.1393,\n",
      "          0.1463, -0.0333, -0.1641,  0.0098, -0.0897,  0.1031]],\n",
      "       grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_tanh_stack.8.bias | Size: torch.Size([20]) | Values : tensor([-0.0797,  0.0625], grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_tanh_stack.10.weight | Size: torch.Size([20, 20]) | Values : tensor([[ 0.0717, -0.0996,  0.0345,  0.1247,  0.1134,  0.0567, -0.0242,  0.1808,\n",
      "         -0.1768,  0.0660, -0.1372,  0.1581, -0.1300,  0.1631, -0.0752, -0.0383,\n",
      "         -0.1914,  0.1093, -0.0321, -0.1562],\n",
      "        [ 0.1075, -0.0307, -0.0947,  0.1462, -0.0625, -0.2032,  0.2145, -0.1819,\n",
      "         -0.0856, -0.1662,  0.0992,  0.2036, -0.0361, -0.1822, -0.0184, -0.0951,\n",
      "         -0.1318, -0.2056,  0.0580, -0.1273]], grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_tanh_stack.10.bias | Size: torch.Size([20]) | Values : tensor([ 0.1222, -0.1128], grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_tanh_stack.12.weight | Size: torch.Size([10, 20]) | Values : tensor([[-0.2130,  0.0619,  0.1877,  0.1862, -0.0402, -0.1968, -0.1828, -0.1182,\n",
      "         -0.0594, -0.1407, -0.0991, -0.0903, -0.0368, -0.1958,  0.0464,  0.0335,\n",
      "         -0.1344, -0.0901,  0.2151, -0.0662],\n",
      "        [ 0.0695, -0.0836, -0.2136, -0.1445, -0.0495, -0.0787, -0.2200,  0.1900,\n",
      "         -0.1665,  0.1968,  0.0789, -0.0851, -0.1338, -0.1865,  0.2148,  0.1497,\n",
      "          0.1924, -0.1310,  0.1631, -0.0854]], grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_tanh_stack.12.bias | Size: torch.Size([10]) | Values : tensor([0.1402, 0.1380], grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_tanh_stack.14.weight | Size: torch.Size([1, 10]) | Values : tensor([[ 0.2429, -0.0932,  0.3049,  0.1370,  0.1354,  0.0065,  0.2928,  0.2116,\n",
      "         -0.2899,  0.1837]], grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_tanh_stack.14.bias | Size: torch.Size([1]) | Values : tensor([-0.1058], grad_fn=<SliceBackward>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# creating model instance\n",
    "model = NeuralNetwork()\n",
    "print(model)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")\n",
    "    \n",
    "# initialising hyperparameters\n",
    "learning_rate = 1e-2\n",
    "epochs = 30\n",
    "\n",
    "# initializing the loss function\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# initializing the optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 226,
=======
   "execution_count": 73,
   "id": "5beb2a2b",
>>>>>>> ba920bf3302ab53c98e7a1cce9c3825755fed9cf
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining train and test loops\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss}  [{current}/{size}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Test Error: Avg loss: {test_loss} \\n\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 227,
=======
   "execution_count": 74,
   "id": "75a488c5",
>>>>>>> ba920bf3302ab53c98e7a1cce9c3825755fed9cf
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.06599419564008713  [0/7511]\n",
      "loss: 3.549129542079754e-05  [500/7511]\n",
      "loss: 2.7093669814348686e-06  [1000/7511]\n",
      "loss: 2.091038140861201e-06  [1500/7511]\n",
      "loss: 2.557143943704432e-06  [2000/7511]\n",
      "loss: 5.205646630201954e-06  [2500/7511]\n",
      "loss: 5.2342361414048355e-06  [3000/7511]\n",
      "loss: 5.806089689031069e-07  [3500/7511]\n",
      "loss: 1.4413216149478103e-06  [4000/7511]\n",
      "loss: 9.382137591273931e-07  [4500/7511]\n",
      "loss: 6.605012004001765e-07  [5000/7511]\n",
      "loss: 5.360730028769467e-07  [5500/7511]\n",
      "loss: 5.868647576789954e-07  [6000/7511]\n",
      "loss: 7.435410793732444e-07  [6500/7511]\n",
      "loss: 3.601078333304031e-06  [7000/7511]\n",
      "loss: 1.2049871429553605e-06  [7500/7511]\n",
      "Test Error: Avg loss: 2.039120240345549e-06 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 6.581251454917947e-07  [0/7511]\n",
      "loss: 8.051171676015656e-07  [500/7511]\n",
      "loss: 7.884781894063053e-07  [1000/7511]\n",
      "loss: 2.7524042707227636e-06  [1500/7511]\n",
      "loss: 4.677245044604206e-07  [2000/7511]\n",
      "loss: 2.5707856821099995e-06  [2500/7511]\n",
      "loss: 8.659405352773319e-07  [3000/7511]\n",
      "loss: 2.446277676426689e-06  [3500/7511]\n",
      "loss: 7.049293344607577e-07  [4000/7511]\n",
      "loss: 7.54619804865797e-07  [4500/7511]\n",
      "loss: 4.41236920778465e-07  [5000/7511]\n",
      "loss: 2.9963914016661874e-07  [5500/7511]\n",
      "loss: 1.6795871715657995e-07  [6000/7511]\n",
      "loss: 3.1692429729446303e-06  [6500/7511]\n",
      "loss: 3.198070430698863e-07  [7000/7511]\n",
      "loss: 1.5102251609278028e-06  [7500/7511]\n",
      "Test Error: Avg loss: 1.4999754929480224e-06 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.2724480029646656e-06  [0/7511]\n",
      "loss: 6.398870482371422e-07  [500/7511]\n",
      "loss: 8.576298569096252e-07  [1000/7511]\n",
      "loss: 1.4878593901812565e-05  [1500/7511]\n",
      "loss: 5.495443815561885e-07  [2000/7511]\n",
      "loss: 3.085292519244831e-06  [2500/7511]\n",
      "loss: 1.3007797861064319e-06  [3000/7511]\n",
      "loss: 2.0229399524396285e-06  [3500/7511]\n",
      "loss: 6.227016910997918e-07  [4000/7511]\n",
      "loss: 2.700108439057658e-07  [4500/7511]\n",
      "loss: 4.897066787634685e-07  [5000/7511]\n",
      "loss: 2.36659798247274e-06  [5500/7511]\n",
      "loss: 1.0859480426006485e-06  [6000/7511]\n",
      "loss: 4.1266429207098554e-07  [6500/7511]\n",
      "loss: 1.111002802645089e-06  [7000/7511]\n",
      "loss: 3.268931436650746e-07  [7500/7511]\n",
      "Test Error: Avg loss: 1.2029832052025634e-06 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 4.5312043539524893e-07  [0/7511]\n",
      "loss: 4.5937528625472623e-07  [500/7511]\n",
      "loss: 1.4609701111112372e-06  [1000/7511]\n",
      "loss: 9.370697853228194e-07  [1500/7511]\n",
      "loss: 2.4801474296509696e-07  [2000/7511]\n",
      "loss: 3.410052897834248e-07  [2500/7511]\n",
      "loss: 3.795884367718827e-06  [3000/7511]\n",
      "loss: 6.849238616268849e-07  [3500/7511]\n",
      "loss: 2.440891080368601e-07  [4000/7511]\n",
      "loss: 1.196947550852201e-06  [4500/7511]\n",
      "loss: 5.231234467828472e-07  [5000/7511]\n",
      "loss: 4.7030096084199613e-07  [5500/7511]\n",
      "loss: 2.5675979031802854e-06  [6000/7511]\n",
      "loss: 1.599194661139336e-07  [6500/7511]\n",
      "loss: 1.4114301620793412e-06  [7000/7511]\n",
      "loss: 3.1425028623743856e-07  [7500/7511]\n",
      "Test Error: Avg loss: 1.0316441743220885e-06 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 2.0854328397490463e-07  [0/7511]\n",
      "loss: 1.6464925067793956e-07  [500/7511]\n",
      "loss: 4.4074752736378286e-07  [1000/7511]\n",
      "loss: 8.059858487285965e-07  [1500/7511]\n",
      "loss: 1.5396904018416535e-06  [2000/7511]\n",
      "loss: 2.6465019686838787e-07  [2500/7511]\n",
      "loss: 7.163935720200243e-07  [3000/7511]\n",
      "loss: 1.9003405782314076e-07  [3500/7511]\n",
      "loss: 7.645510322618065e-07  [4000/7511]\n",
      "loss: 5.238713356447988e-07  [4500/7511]\n",
      "loss: 5.531530860025669e-07  [5000/7511]\n",
      "loss: 2.5707072381919716e-07  [5500/7511]\n",
      "loss: 1.416592226632929e-06  [6000/7511]\n",
      "loss: 6.445732481097366e-08  [6500/7511]\n",
      "loss: 3.583710963539488e-07  [7000/7511]\n",
      "loss: 5.820390288135968e-05  [7500/7511]\n",
      "Test Error: Avg loss: 9.85685795946532e-07 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 6.487222208306775e-07  [0/7511]\n",
      "loss: 2.840644697243988e-07  [500/7511]\n",
      "loss: 6.097141636018932e-07  [1000/7511]\n",
      "loss: 8.918812710589918e-08  [1500/7511]\n",
      "loss: 5.63099149530899e-07  [2000/7511]\n",
      "loss: 2.475125711498549e-06  [2500/7511]\n",
      "loss: 1.5899028085186728e-06  [3000/7511]\n",
      "loss: 1.9292106401280762e-07  [3500/7511]\n",
      "loss: 3.595934288114222e-07  [4000/7511]\n",
      "loss: 1.4788047337788157e-06  [4500/7511]\n",
      "loss: 1.321137574450404e-06  [5000/7511]\n",
      "loss: 2.0767612340932828e-07  [5500/7511]\n",
      "loss: 1.338140123152698e-07  [6000/7511]\n",
      "loss: 2.2379732911304018e-07  [6500/7511]\n",
      "loss: 1.343647966223216e-07  [7000/7511]\n",
      "loss: 1.6356851517684845e-07  [7500/7511]\n",
      "Test Error: Avg loss: 8.209983780297269e-07 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 3.686337777253357e-07  [0/7511]\n",
      "loss: 1.5297759148324985e-07  [500/7511]\n",
      "loss: 1.2875664197053993e-06  [1000/7511]\n",
      "loss: 5.724606353396666e-07  [1500/7511]\n",
      "loss: 1.9131005046801874e-07  [2000/7511]\n",
      "loss: 9.234551043846295e-07  [2500/7511]\n",
      "loss: 2.2380964992407826e-07  [3000/7511]\n",
      "loss: 1.6743204866997985e-07  [3500/7511]\n",
      "loss: 1.904877535707783e-06  [4000/7511]\n",
      "loss: 8.827291253510339e-07  [4500/7511]\n",
      "loss: 1.5460230997632607e-06  [5000/7511]\n",
      "loss: 5.631464432553912e-07  [5500/7511]\n",
      "loss: 5.661315185534477e-07  [6000/7511]\n",
      "loss: 2.266974803433186e-07  [6500/7511]\n",
      "loss: 2.176997895730892e-06  [7000/7511]\n",
      "loss: 3.605167080422689e-07  [7500/7511]\n",
      "Test Error: Avg loss: 7.795775381274942e-07 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.4861441854918667e-07  [0/7511]\n",
      "loss: 2.6376895334578876e-07  [500/7511]\n",
      "loss: 1.3732774277741555e-06  [1000/7511]\n",
      "loss: 4.1308732079414767e-07  [1500/7511]\n",
      "loss: 2.086719916860602e-07  [2000/7511]\n",
      "loss: 4.817181888938649e-07  [2500/7511]\n",
      "loss: 2.5929469416041684e-07  [3000/7511]\n",
      "loss: 6.865691375423921e-06  [3500/7511]\n",
      "loss: 5.200836881158466e-07  [4000/7511]\n",
      "loss: 3.282897580447752e-07  [4500/7511]\n",
      "loss: 1.1820402789908258e-07  [5000/7511]\n",
      "loss: 1.126528673012217e-06  [5500/7511]\n",
      "loss: 1.889230816232157e-07  [6000/7511]\n",
      "loss: 1.807117939733871e-07  [6500/7511]\n",
      "loss: 1.8020462277945626e-07  [7000/7511]\n",
      "loss: 2.0678367036452983e-06  [7500/7511]\n",
      "Test Error: Avg loss: 7.260965662128207e-07 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 2.181917352572782e-06  [0/7511]\n",
      "loss: 3.888274022756377e-07  [500/7511]\n",
      "loss: 3.2483373502145696e-07  [1000/7511]\n",
      "loss: 3.234886776226631e-07  [1500/7511]\n",
      "loss: 8.859843347863716e-08  [2000/7511]\n",
      "loss: 5.650445018545724e-07  [2500/7511]\n",
      "loss: 2.5140172965620877e-07  [3000/7511]\n",
      "loss: 2.3117576120057493e-07  [3500/7511]\n",
      "loss: 2.129165466158156e-07  [4000/7511]\n",
      "loss: 1.0634088454253288e-07  [4500/7511]\n",
      "loss: 4.087146123765706e-07  [5000/7511]\n",
      "loss: 2.82141741081432e-07  [5500/7511]\n",
      "loss: 1.2150085240136832e-06  [6000/7511]\n",
      "loss: 3.4739619536594546e-07  [6500/7511]\n",
      "loss: 9.119598587403743e-08  [7000/7511]\n",
      "loss: 8.198869494435712e-08  [7500/7511]\n",
      "Test Error: Avg loss: 7.181269843322632e-07 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 4.573728347168071e-06  [0/7511]\n",
      "loss: 1.341434341384229e-07  [500/7511]\n",
      "loss: 3.174020832830138e-07  [1000/7511]\n",
      "loss: 5.160209752830269e-07  [1500/7511]\n",
      "loss: 3.9369859905491467e-07  [2000/7511]\n",
      "loss: 1.1708805658372512e-07  [2500/7511]\n",
      "loss: 3.790935920733318e-07  [3000/7511]\n",
      "loss: 4.746524382426287e-07  [3500/7511]\n",
      "loss: 4.2309707737331337e-07  [4000/7511]\n",
      "loss: 1.1571365376994436e-07  [4500/7511]\n",
      "loss: 1.262558697590066e-07  [5000/7511]\n",
      "loss: 6.338358957691526e-07  [5500/7511]\n",
      "loss: 5.225090262683807e-07  [6000/7511]\n",
      "loss: 3.2953747108876996e-07  [6500/7511]\n",
      "loss: 3.9098281945371127e-07  [7000/7511]\n",
      "loss: 8.379670646263548e-08  [7500/7511]\n",
      "Test Error: Avg loss: 6.745469837247295e-07 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 1.6554403714508226e-07  [0/7511]\n",
      "loss: 1.7458074808018864e-07  [500/7511]\n",
      "loss: 9.322619121121534e-08  [1000/7511]\n",
      "loss: 7.052640285110101e-07  [1500/7511]\n",
      "loss: 1.6568518503845553e-06  [2000/7511]\n",
      "loss: 6.582109790542745e-07  [2500/7511]\n",
      "loss: 2.4143307086887944e-07  [3000/7511]\n",
      "loss: 3.0052385682211025e-06  [3500/7511]\n",
      "loss: 1.424940307970246e-07  [4000/7511]\n",
      "loss: 1.576069621478382e-06  [4500/7511]\n",
      "loss: 5.81402090915617e-08  [5000/7511]\n",
      "loss: 6.463017143687466e-07  [5500/7511]\n",
      "loss: 9.789191324216517e-08  [6000/7511]\n",
      "loss: 1.7528336684335954e-06  [6500/7511]\n",
      "loss: 4.307002257064596e-07  [7000/7511]\n",
      "loss: 1.1581543901684199e-07  [7500/7511]\n",
      "Test Error: Avg loss: 6.866311114218366e-07 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 1.8626305973157287e-06  [0/7511]\n",
      "loss: 1.6079093256848864e-06  [500/7511]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.90345858186447e-07  [1000/7511]\n",
      "loss: 2.9485352115443675e-07  [1500/7511]\n",
      "loss: 6.858676897536498e-07  [2000/7511]\n",
      "loss: 4.6163668798726576e-07  [2500/7511]\n",
      "loss: 2.4837100909280707e-07  [3000/7511]\n",
      "loss: 3.2105683089866943e-07  [3500/7511]\n",
      "loss: 6.774126632080879e-06  [4000/7511]\n",
      "loss: 2.142692920870104e-07  [4500/7511]\n",
      "loss: 1.248153296273813e-07  [5000/7511]\n",
      "loss: 1.6675326719450823e-07  [5500/7511]\n",
      "loss: 5.883610469936684e-07  [6000/7511]\n",
      "loss: 2.4462578949169256e-06  [6500/7511]\n",
      "loss: 8.77375612162723e-08  [7000/7511]\n",
      "loss: 2.4633845896460116e-07  [7500/7511]\n",
      "Test Error: Avg loss: 6.838884585151199e-07 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 3.1122320365284395e-07  [0/7511]\n",
      "loss: 1.0688959406479626e-07  [500/7511]\n",
      "loss: 7.554561420874961e-07  [1000/7511]\n",
      "loss: 2.2072546812523797e-07  [1500/7511]\n",
      "loss: 5.852347229051702e-08  [2000/7511]\n",
      "loss: 4.0250179722534085e-07  [2500/7511]\n",
      "loss: 6.322582066786708e-07  [3000/7511]\n",
      "loss: 1.0957605809380766e-06  [3500/7511]\n",
      "loss: 4.141637930388242e-07  [4000/7511]\n",
      "loss: 1.2494259635786875e-06  [4500/7511]\n",
      "loss: 2.197315183138926e-07  [5000/7511]\n",
      "loss: 1.1503925634315237e-07  [5500/7511]\n",
      "loss: 3.3118010378530016e-07  [6000/7511]\n",
      "loss: 2.2447075309628417e-07  [6500/7511]\n",
      "loss: 5.08634570905997e-07  [7000/7511]\n",
      "loss: 4.1697748542901536e-07  [7500/7511]\n",
      "Test Error: Avg loss: 6.469777771328339e-07 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 1.701552605481993e-07  [0/7511]\n",
      "loss: 1.4987749352712854e-07  [500/7511]\n",
      "loss: 1.0493558733060127e-07  [1000/7511]\n",
      "loss: 3.9641818148083985e-06  [1500/7511]\n",
      "loss: 7.001284529906115e-07  [2000/7511]\n",
      "loss: 2.415787889731291e-07  [2500/7511]\n",
      "loss: 1.0150936446962078e-07  [3000/7511]\n",
      "loss: 1.3406842924723605e-07  [3500/7511]\n",
      "loss: 5.590250111708883e-07  [4000/7511]\n",
      "loss: 1.1246766717931678e-07  [4500/7511]\n",
      "loss: 1.7696293070912361e-06  [5000/7511]\n",
      "loss: 6.393977400875883e-07  [5500/7511]\n",
      "loss: 2.4771486550889676e-07  [6000/7511]\n",
      "loss: 1.8375894228483958e-07  [6500/7511]\n",
      "loss: 3.3646142583165783e-07  [7000/7511]\n",
      "loss: 1.3401410114965984e-07  [7500/7511]\n",
      "Test Error: Avg loss: 6.343343808594872e-07 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 1.1613670949373045e-06  [0/7511]\n",
      "loss: 6.941087576706195e-06  [500/7511]\n",
      "loss: 1.2327691933933238e-07  [1000/7511]\n",
      "loss: 2.7846860817248853e-08  [1500/7511]\n",
      "loss: 9.2662560291501e-08  [2000/7511]\n",
      "loss: 2.9920371957814496e-07  [2500/7511]\n",
      "loss: 2.0271450011932757e-06  [3000/7511]\n",
      "loss: 1.072736068863378e-07  [3500/7511]\n",
      "loss: 1.3873105331185798e-07  [4000/7511]\n",
      "loss: 2.5797783109737793e-07  [4500/7511]\n",
      "loss: 2.976436917379033e-06  [5000/7511]\n",
      "loss: 3.3204571536771255e-07  [5500/7511]\n",
      "loss: 2.195192223553022e-07  [6000/7511]\n",
      "loss: 2.836129624483874e-07  [6500/7511]\n",
      "loss: 1.7090238202399632e-07  [7000/7511]\n",
      "loss: 4.1741568566067144e-06  [7500/7511]\n",
      "Test Error: Avg loss: 6.214092089784629e-07 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 7.454855222022161e-08  [0/7511]\n",
      "loss: 1.869095967776957e-06  [500/7511]\n",
      "loss: 1.9716917165624182e-07  [1000/7511]\n",
      "loss: 2.972968786707497e-07  [1500/7511]\n",
      "loss: 1.981260311367805e-07  [2000/7511]\n",
      "loss: 7.889435437391512e-06  [2500/7511]\n",
      "loss: 2.1800246940983925e-06  [3000/7511]\n",
      "loss: 1.6619073051060695e-07  [3500/7511]\n",
      "loss: 1.739246755505519e-07  [4000/7511]\n",
      "loss: 1.080317179003032e-05  [4500/7511]\n",
      "loss: 3.2787124837341253e-07  [5000/7511]\n",
      "loss: 2.2235106200696464e-07  [5500/7511]\n",
      "loss: 4.939867267239606e-06  [6000/7511]\n",
      "loss: 4.6648818852190743e-07  [6500/7511]\n",
      "loss: 1.7484680370216665e-07  [7000/7511]\n",
      "loss: 1.9959782093792455e-07  [7500/7511]\n",
      "Test Error: Avg loss: 6.240266063028758e-07 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 2.3122699985833606e-06  [0/7511]\n",
      "loss: 5.061950787421665e-07  [500/7511]\n",
      "loss: 2.3609742072494555e-07  [1000/7511]\n",
      "loss: 9.178473305837542e-07  [1500/7511]\n",
      "loss: 2.1799922933496418e-07  [2000/7511]\n",
      "loss: 1.1223968954254815e-07  [2500/7511]\n",
      "loss: 2.1125117655174108e-07  [3000/7511]\n",
      "loss: 2.1152027329662815e-07  [3500/7511]\n",
      "loss: 5.065493837719259e-07  [4000/7511]\n",
      "loss: 4.301084004509903e-07  [4500/7511]\n",
      "loss: 1.18733424869788e-07  [5000/7511]\n",
      "loss: 1.9537933440005872e-06  [5500/7511]\n",
      "loss: 3.3223892614842043e-07  [6000/7511]\n",
      "loss: 2.0014414303659578e-07  [6500/7511]\n",
      "loss: 1.5685841958656965e-07  [7000/7511]\n",
      "loss: 2.3105395996481093e-07  [7500/7511]\n",
      "Test Error: Avg loss: 6.14731123936985e-07 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 2.4093154138427053e-07  [0/7511]\n",
      "loss: 2.6824326937457954e-07  [500/7511]\n",
      "loss: 3.0686263130519364e-07  [1000/7511]\n",
      "loss: 2.8903531301693874e-07  [1500/7511]\n",
      "loss: 4.537938309567835e-07  [2000/7511]\n",
      "loss: 1.1122386922579608e-06  [2500/7511]\n",
      "loss: 3.1177191317510733e-07  [3000/7511]\n",
      "loss: 1.542103547080842e-07  [3500/7511]\n",
      "loss: 3.0469257694676344e-07  [4000/7511]\n",
      "loss: 2.955480340460781e-07  [4500/7511]\n",
      "loss: 1.483982288164043e-07  [5000/7511]\n",
      "loss: 3.0455601063295035e-07  [5500/7511]\n",
      "loss: 1.299574989843677e-07  [6000/7511]\n",
      "loss: 2.0341272488622053e-07  [6500/7511]\n",
      "loss: 2.478569740560488e-07  [7000/7511]\n",
      "loss: 1.948851462429957e-07  [7500/7511]\n",
      "Test Error: Avg loss: 5.992979925044013e-07 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 1.0397246796856052e-06  [0/7511]\n",
      "loss: 1.9466766332243424e-07  [500/7511]\n",
      "loss: 1.5571826850191428e-07  [1000/7511]\n",
      "loss: 2.005177293540328e-06  [1500/7511]\n",
      "loss: 1.9613749202562758e-07  [2000/7511]\n",
      "loss: 7.028012873888656e-07  [2500/7511]\n",
      "loss: 3.3674655242066365e-07  [3000/7511]\n",
      "loss: 8.852746447018944e-08  [3500/7511]\n",
      "loss: 1.5097077721293317e-07  [4000/7511]\n",
      "loss: 9.566026193397192e-08  [4500/7511]\n",
      "loss: 1.5576610223888565e-07  [5000/7511]\n",
      "loss: 1.3231924356205127e-07  [5500/7511]\n",
      "loss: 5.2996796284787706e-08  [6000/7511]\n",
      "loss: 1.8025492636297713e-06  [6500/7511]\n",
      "loss: 1.8862705530864332e-07  [7000/7511]\n",
      "loss: 1.4133546528682928e-06  [7500/7511]\n",
      "Test Error: Avg loss: 5.97104632004965e-07 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 2.0603334860425093e-07  [0/7511]\n",
      "loss: 2.1471495870173385e-07  [500/7511]\n",
      "loss: 1.73431828898174e-07  [1000/7511]\n",
      "loss: 4.6047910018387483e-07  [1500/7511]\n",
      "loss: 2.4990310976136243e-07  [2000/7511]\n",
      "loss: 1.1155648280691821e-06  [2500/7511]\n",
      "loss: 1.2600249021943455e-07  [3000/7511]\n",
      "loss: 2.0202216433062858e-07  [3500/7511]\n",
      "loss: 2.3479390165448422e-07  [4000/7511]\n",
      "loss: 2.97210192456987e-07  [4500/7511]\n",
      "loss: 8.928314798595238e-08  [5000/7511]\n",
      "loss: 1.3612226723580534e-07  [5500/7511]\n",
      "loss: 1.2782741976025136e-07  [6000/7511]\n",
      "loss: 4.228575960496528e-07  [6500/7511]\n",
      "loss: 2.644696337483765e-07  [7000/7511]\n",
      "loss: 3.199008347110066e-07  [7500/7511]\n",
      "Test Error: Avg loss: 5.913095804800503e-07 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 1.6918795608944492e-07  [0/7511]\n",
      "loss: 2.975741324462433e-07  [500/7511]\n",
      "loss: 2.1195373847149312e-06  [1000/7511]\n",
      "loss: 3.7002456565460307e-07  [1500/7511]\n",
      "loss: 3.732884579221718e-07  [2000/7511]\n",
      "loss: 9.623104801903537e-08  [2500/7511]\n",
      "loss: 1.6792087365047337e-07  [3000/7511]\n",
      "loss: 3.6432692240850884e-07  [3500/7511]\n",
      "loss: 1.23521488148981e-07  [4000/7511]\n",
      "loss: 1.9334390799485845e-07  [4500/7511]\n",
      "loss: 1.3366387463520368e-07  [5000/7511]\n",
      "loss: 3.345698189605173e-07  [5500/7511]\n",
      "loss: 4.1490707758384815e-07  [6000/7511]\n",
      "loss: 1.3086913952520263e-07  [6500/7511]\n",
      "loss: 3.422038901135238e-07  [7000/7511]\n",
      "loss: 1.1878630346018326e-07  [7500/7511]\n",
      "Test Error: Avg loss: 5.841755357737929e-07 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 3.5673645015776856e-07  [0/7511]\n",
      "loss: 4.689647141731257e-07  [500/7511]\n",
      "loss: 1.4901401357292343e-07  [1000/7511]\n",
      "loss: 1.0688696505667394e-07  [1500/7511]\n",
      "loss: 2.3046720798447495e-07  [2000/7511]\n",
      "loss: 1.1067049854318611e-06  [2500/7511]\n",
      "loss: 3.027743105121772e-07  [3000/7511]\n",
      "loss: 1.3758534578300896e-07  [3500/7511]\n",
      "loss: 3.5030959111281845e-07  [4000/7511]\n",
      "loss: 1.0117214799265639e-07  [4500/7511]\n",
      "loss: 1.9847644239234796e-07  [5000/7511]\n",
      "loss: 9.722144511670194e-08  [5500/7511]\n",
      "loss: 2.6220922677566705e-07  [6000/7511]\n",
      "loss: 3.644771027211391e-07  [6500/7511]\n",
      "loss: 4.049613835377386e-07  [7000/7511]\n",
      "loss: 9.929069619829534e-07  [7500/7511]\n",
      "Test Error: Avg loss: 5.874687095406021e-07 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 1.67055361544044e-07  [0/7511]\n",
      "loss: 1.9808105662377784e-06  [500/7511]\n",
      "loss: 1.0419339702139041e-07  [1000/7511]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.5359070459908253e-07  [1500/7511]\n",
      "loss: 2.680492627860076e-07  [2000/7511]\n",
      "loss: 3.794679628299491e-07  [2500/7511]\n",
      "loss: 2.9724341743531113e-07  [3000/7511]\n",
      "loss: 6.272384780459106e-06  [3500/7511]\n",
      "loss: 1.922559391687173e-07  [4000/7511]\n",
      "loss: 1.849083872684787e-07  [4500/7511]\n",
      "loss: 1.7674068431006162e-06  [5000/7511]\n",
      "loss: 3.6020914251366776e-08  [5500/7511]\n",
      "loss: 2.886356469389284e-07  [6000/7511]\n",
      "loss: 3.20599338010652e-06  [6500/7511]\n",
      "loss: 3.7558456256192585e-07  [7000/7511]\n",
      "loss: 2.907531779783312e-07  [7500/7511]\n",
      "Test Error: Avg loss: 5.720743259838718e-07 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 1.2577283996506594e-05  [0/7511]\n",
      "loss: 1.3907964557802188e-07  [500/7511]\n",
      "loss: 2.3447014996236248e-07  [1000/7511]\n",
      "loss: 1.7938451435384195e-07  [1500/7511]\n",
      "loss: 2.1132147765001719e-07  [2000/7511]\n",
      "loss: 6.664499778707977e-07  [2500/7511]\n",
      "loss: 9.72393010556516e-08  [3000/7511]\n",
      "loss: 1.1042684633366662e-07  [3500/7511]\n",
      "loss: 5.876070190424798e-07  [4000/7511]\n",
      "loss: 6.720259534631623e-06  [4500/7511]\n",
      "loss: 8.215286584345449e-07  [5000/7511]\n",
      "loss: 3.375110111392132e-07  [5500/7511]\n",
      "loss: 3.560410846148443e-07  [6000/7511]\n",
      "loss: 3.568349313809449e-07  [6500/7511]\n",
      "loss: 9.412647727913281e-08  [7000/7511]\n",
      "loss: 1.6752206022374594e-07  [7500/7511]\n",
      "Test Error: Avg loss: 5.768944128035439e-07 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 4.2633939756342443e-07  [0/7511]\n",
      "loss: 3.453807835285261e-07  [500/7511]\n",
      "loss: 6.398990848310859e-08  [1000/7511]\n",
      "loss: 1.9869271739025862e-07  [1500/7511]\n",
      "loss: 1.3049627511918516e-07  [2000/7511]\n",
      "loss: 1.0932138394537105e-07  [2500/7511]\n",
      "loss: 3.367901797446393e-07  [3000/7511]\n",
      "loss: 2.2722753101334092e-07  [3500/7511]\n",
      "loss: 1.3707275456908974e-06  [4000/7511]\n",
      "loss: 7.037518798824749e-07  [4500/7511]\n",
      "loss: 9.204084676639468e-07  [5000/7511]\n",
      "loss: 1.2705900189757813e-06  [5500/7511]\n",
      "loss: 2.6241207251587184e-07  [6000/7511]\n",
      "loss: 5.971489827061305e-07  [6500/7511]\n",
      "loss: 4.667202802011161e-07  [7000/7511]\n",
      "loss: 1.8618500519096415e-07  [7500/7511]\n",
      "Test Error: Avg loss: 5.799057158682808e-07 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 2.57562277283796e-07  [0/7511]\n",
      "loss: 1.8259423484323634e-07  [500/7511]\n",
      "loss: 2.3923323055896617e-07  [1000/7511]\n",
      "loss: 1.8599703821564617e-07  [1500/7511]\n",
      "loss: 1.170371817238447e-07  [2000/7511]\n",
      "loss: 8.358662171303877e-07  [2500/7511]\n",
      "loss: 3.98485099140089e-07  [3000/7511]\n",
      "loss: 1.524612343928311e-06  [3500/7511]\n",
      "loss: 2.1472742446349002e-06  [4000/7511]\n",
      "loss: 1.7372198612974898e-07  [4500/7511]\n",
      "loss: 4.393768620047922e-07  [5000/7511]\n",
      "loss: 1.988419882081871e-07  [5500/7511]\n",
      "loss: 1.0558943586147507e-07  [6000/7511]\n",
      "loss: 3.3176630154230224e-07  [6500/7511]\n",
      "loss: 1.2301343588205782e-07  [7000/7511]\n",
      "loss: 3.4095953083124186e-07  [7500/7511]\n",
      "Test Error: Avg loss: 5.682699977718598e-07 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 4.4617377170652617e-07  [0/7511]\n",
      "loss: 1.192165228758313e-07  [500/7511]\n",
      "loss: 2.083772301375575e-07  [1000/7511]\n",
      "loss: 2.151082867385412e-07  [1500/7511]\n",
      "loss: 7.846941798561602e-07  [2000/7511]\n",
      "loss: 9.735945241118316e-07  [2500/7511]\n",
      "loss: 4.4183084924043214e-07  [3000/7511]\n",
      "loss: 2.6862130653171334e-07  [3500/7511]\n",
      "loss: 1.5993744284514833e-07  [4000/7511]\n",
      "loss: 1.705702317167379e-07  [4500/7511]\n",
      "loss: 1.9741719370358624e-07  [5000/7511]\n",
      "loss: 7.899327414406798e-08  [5500/7511]\n",
      "loss: 7.858915296310442e-08  [6000/7511]\n",
      "loss: 1.384401713266925e-07  [6500/7511]\n",
      "loss: 1.9715121197805274e-06  [7000/7511]\n",
      "loss: 3.716960463862051e-07  [7500/7511]\n",
      "Test Error: Avg loss: 5.604867722791803e-07 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 3.741957144143271e-08  [0/7511]\n",
      "loss: 2.4841053800628288e-06  [500/7511]\n",
      "loss: 1.9503542603160895e-07  [1000/7511]\n",
      "loss: 3.428900470225926e-07  [1500/7511]\n",
      "loss: 1.2117351388951647e-07  [2000/7511]\n",
      "loss: 1.4956764005091827e-07  [2500/7511]\n",
      "loss: 8.372454090022075e-07  [3000/7511]\n",
      "loss: 4.174167713699717e-07  [3500/7511]\n",
      "loss: 3.8598022911173757e-07  [4000/7511]\n",
      "loss: 9.730993042467162e-07  [4500/7511]\n",
      "loss: 8.707457510581662e-08  [5000/7511]\n",
      "loss: 2.0617785878584982e-07  [5500/7511]\n",
      "loss: 2.1536314420700364e-07  [6000/7511]\n",
      "loss: 1.4745310750186036e-07  [6500/7511]\n",
      "loss: 1.2775086588590057e-07  [7000/7511]\n",
      "loss: 2.0195582806081802e-07  [7500/7511]\n",
      "Test Error: Avg loss: 5.511325149959893e-07 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 2.008820985111015e-07  [0/7511]\n",
      "loss: 2.252522790513467e-06  [500/7511]\n",
      "loss: 1.9906112811440835e-06  [1000/7511]\n",
      "loss: 2.4333412511623465e-06  [1500/7511]\n",
      "loss: 1.9472992107694154e-07  [2000/7511]\n",
      "loss: 6.657327276116121e-07  [2500/7511]\n",
      "loss: 2.8734686452480673e-07  [3000/7511]\n",
      "loss: 1.6532540314528887e-07  [3500/7511]\n",
      "loss: 6.33349316103704e-07  [4000/7511]\n",
      "loss: 1.9070212431415712e-07  [4500/7511]\n",
      "loss: 9.346788232278413e-08  [5000/7511]\n",
      "loss: 1.353720620045351e-07  [5500/7511]\n",
      "loss: 8.361839718418196e-07  [6000/7511]\n",
      "loss: 2.7426108317740727e-07  [6500/7511]\n",
      "loss: 1.932741326982068e-07  [7000/7511]\n",
      "loss: 1.4533887338075147e-07  [7500/7511]\n",
      "Test Error: Avg loss: 5.499880552833454e-07 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 3.5555680710785964e-07  [0/7511]\n",
      "loss: 2.6263794552505715e-06  [500/7511]\n",
      "loss: 3.8568461491195194e-07  [1000/7511]\n",
      "loss: 3.466755416070555e-08  [1500/7511]\n",
      "loss: 1.6486474407884089e-07  [2000/7511]\n",
      "loss: 7.616118580244802e-08  [2500/7511]\n",
      "loss: 1.532612941446132e-06  [3000/7511]\n",
      "loss: 1.96855853573652e-06  [3500/7511]\n",
      "loss: 2.095514446409652e-06  [4000/7511]\n",
      "loss: 5.049334959039697e-07  [4500/7511]\n",
      "loss: 2.0771580011569313e-07  [5000/7511]\n",
      "loss: 3.3493165574327577e-07  [5500/7511]\n",
      "loss: 1.5977817611201317e-06  [6000/7511]\n",
      "loss: 1.3099570139729622e-07  [6500/7511]\n",
      "loss: 2.1864056520826125e-07  [7000/7511]\n",
      "loss: 9.088675767543464e-08  [7500/7511]\n",
      "Test Error: Avg loss: 5.543958513383419e-07 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# executing training and testing\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_ldr, model, loss_fn, optimizer)\n",
    "    test_loop(test_ldr, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68bf01e",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13063b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First NN model architecture\n",
    "class NeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.linear_relu_stack = torch.nn.Sequential(\n",
    "            torch.nn.Linear(82, 30),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(30, 30),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(30, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        pred_conc = self.linear_relu_stack(x)\n",
    "        return pred_conc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3e458d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to scale and transform input data\n",
    "def get_data(X, y):\n",
    "    X = X.values\n",
    "    y = y.values\n",
    "    # scaling the data\n",
    "    feature_scaler = StandardScaler()\n",
    "    X = feature_scaler.fit_transform(X)\n",
    "    return X, y\n",
    "\n",
    "# acquiring transformed data\n",
    "X_arr, y_arr = get_data(X, y)\n",
    "\n",
    "# splitting into test and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_arr, y_arr, test_size=0.3)\n",
    "cols = np.array(X.columns)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
